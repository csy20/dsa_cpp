# Datastores

## What is a Datastore?

**Persistent storage systems for structured/unstructured data**

```
Application â†” Datastore
             â”œâ”€ Relational (SQL)
             â”œâ”€ NoSQL (KV, Document, Wide-column, Graph)
             â”œâ”€ NewSQL (distributed SQL)
             â”œâ”€ OLAP (analytics)
             â””â”€ Vector DB (embeddings)

Choose based on:
â”œâ”€ Data structure (structured vs unstructured)
â”œâ”€ Access patterns (OLTP vs OLAP)
â”œâ”€ Scale requirements (single vs distributed)
â”œâ”€ Consistency needs (ACID vs BASE)
â””â”€ Query complexity (joins vs simple lookups)
```

---

## 1. Relational Databases (SQL)

**Structured data with relationships, strong consistency (ACID)**

**Examples:** PostgreSQL, MySQL, Oracle, SQL Server

### 1.1 ACID Properties

**ACID = Atomicity, Consistency, Isolation, Durability**

#### Atomicity (All or Nothing)

```
Transaction: Transfer $100 from Alice to Bob

BEGIN TRANSACTION;
UPDATE accounts SET balance = balance - 100 WHERE user = 'Alice';
UPDATE accounts SET balance = balance + 100 WHERE user = 'Bob';
COMMIT;

Scenarios:
âœ“ Both updates succeed â†’ Transaction commits
âœ— Second update fails â†’ Both updates rolled back (atomicity)
âœ— Crash before commit â†’ Both updates rolled back

Result: Either both happen or neither happens (no partial state)
```

**How it works:**
```
Write-Ahead Log (WAL):
1. Before modifying data, write intent to log
2. Log entry: "Planning to deduct $100 from Alice, add $100 to Bob"
3. Apply changes to database
4. Commit log entry: "Transaction complete"

If crash happens:
â”œâ”€ Before commit: Undo changes using log (rollback)
â””â”€ After commit: Redo changes using log (recovery)

Log ensures atomicity!
```

#### Consistency (Valid State Always)

```
Constraint: balance >= 0

Valid transaction:
Alice: $200 â†’ Transfer $100 â†’ $100 âœ“
Bob: $50 â†’ Receive $100 â†’ $150 âœ“

Invalid transaction:
Alice: $50 â†’ Transfer $100 â†’ -$50 âœ—
Database rejects: Violates constraint (balance < 0)

Transaction rolled back, database stays consistent
```

**Constraints:**
```sql
-- Primary key (unique, not null)
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL
);

-- Foreign key (referential integrity)
CREATE TABLE orders (
    id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(id)  -- Must exist in users table
);

-- Check constraint
CREATE TABLE accounts (
    id SERIAL PRIMARY KEY,
    balance DECIMAL CHECK (balance >= 0)  -- Can't go negative
);

-- Triggers (complex validation)
CREATE TRIGGER check_overdraft
BEFORE UPDATE ON accounts
FOR EACH ROW
EXECUTE FUNCTION validate_balance();
```

#### Isolation (Concurrent Transactions Don't Interfere)

**Isolation Levels:**

```
Problem without isolation:
Time    Transaction A              Transaction B
t1      Read balance: $100
t2                                 Read balance: $100
t3      Withdraw $50 â†’ $50
t4                                 Withdraw $60 â†’ $40
t5      Write $50
t6                                 Write $40  â† Overwrites $50!

Result: Lost update! Should be $100 - $50 - $60 = -$10 (rejected)
```

**Four Isolation Levels:**

| Level | Dirty Read | Non-repeatable Read | Phantom Read | How It Works |
|-------|------------|---------------------|--------------|--------------|
| **Read Uncommitted** | âœ— Allowed | âœ— Allowed | âœ— Allowed | No locks, fastest, unsafe |
| **Read Committed** | âœ“ Prevented | âœ— Allowed | âœ— Allowed | Read locks released after read |
| **Repeatable Read** | âœ“ Prevented | âœ“ Prevented | âœ— Allowed | Read locks held until commit |
| **Serializable** | âœ“ Prevented | âœ“ Prevented | âœ“ Prevented | Full isolation, slowest |

**1. Read Uncommitted (Level 0):**
```
Time    Transaction A              Transaction B
t1      UPDATE balance = 50
t2                                 SELECT balance  â†’ Reads 50 (uncommitted!)
t3      ROLLBACK
t4                                 Uses 50 (dirty data!)

Problem: Dirty read (reading uncommitted data)
Use: Rarely (analytics on approximate data)
```

**2. Read Committed (Level 1) - Most Common:**
```
Time    Transaction A              Transaction B
t1      UPDATE balance = 50
t2                                 SELECT balance  â†’ Reads 100 (committed value)
t3      COMMIT
t4                                 SELECT balance  â†’ Reads 50 (now committed)

âœ“ Prevents dirty reads
âœ— Allows non-repeatable reads (same query, different result)

Use: Default in PostgreSQL, MySQL
```

**3. Repeatable Read (Level 2):**
```
Time    Transaction A              Transaction B
t1      SELECT balance  â†’ 100
t2                                 UPDATE balance = 50
t3                                 COMMIT
t4      SELECT balance  â†’ 100 (snapshot from t1!)

âœ“ Prevents dirty reads
âœ“ Prevents non-repeatable reads (snapshot isolation)
âœ— Allows phantom reads (new rows appear)

Use: Long-running reports
```

**4. Serializable (Level 3):**
```
Transactions execute as if they ran one at a time

Time    Transaction A              Transaction B
t1      BEGIN                      BEGIN
t2      SELECT * FROM accounts     (blocked, waiting for A)
t3      UPDATE ...
t4      COMMIT
t5                                 SELECT * FROM accounts (now runs)

âœ“ Prevents all anomalies
âœ— Slowest (heavy locking)

Use: Financial systems, critical data
```

**Implementation: Locks**

```
Pessimistic Locking (Lock-based):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Transaction A:                      â”‚
â”‚ 1. SELECT ... FOR UPDATE (X-lock)   â”‚
â”‚ 2. Others blocked until commit      â”‚
â”‚ 3. UPDATE ...                       â”‚
â”‚ 4. COMMIT (release lock)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Lock types:
â”œâ”€ Shared (S): Multiple readers
â”œâ”€ Exclusive (X): Single writer
â””â”€ Intent: Hierarchical locking

Problem: Deadlock
  Tx A locks row 1, waits for row 2
  Tx B locks row 2, waits for row 1
  â†’ Database detects, aborts one transaction
```

```
Optimistic Locking (Version-based):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Read data with version           â”‚
â”‚    SELECT balance, version FROM ... â”‚
â”‚    â†’ balance=100, version=5         â”‚
â”‚                                     â”‚
â”‚ 2. User modifies data               â”‚
â”‚                                     â”‚
â”‚ 3. Write with version check         â”‚
â”‚    UPDATE accounts                  â”‚
â”‚    SET balance=50, version=6        â”‚
â”‚    WHERE id=123 AND version=5       â”‚
â”‚                                     â”‚
â”‚ 4. If version changed: 0 rows       â”‚
â”‚    â†’ Retry or fail                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Use: Low contention, web apps
```

**Multi-Version Concurrency Control (MVCC):**
```
PostgreSQL approach:

Each row has multiple versions:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Row ID: 123                        â”‚
â”‚ Version 1 (t1-t3): balance = 100   â”‚
â”‚ Version 2 (t3-t5): balance = 50    â”‚
â”‚ Version 3 (t5-âˆ):  balance = 150   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Transaction at t2: Sees version 1 (100)
Transaction at t4: Sees version 2 (50)
Transaction at t6: Sees version 3 (150)

No read locks needed! Readers don't block writers
Writers create new versions, don't modify old ones

Cleanup: VACUUM removes old versions
```

#### Durability (Survives Crashes)

```
Guarantee: Committed data never lost

How it works:
1. Transaction commits
2. Write to WAL (Write-Ahead Log) on disk
3. WAL synced to disk (fsync)
4. Return "committed" to client
5. Later: Apply WAL to data files (checkpoint)

Crash before checkpoint:
â”œâ”€ Data files incomplete
â””â”€ Replay WAL on restart â†’ Recover committed transactions

WAL is sequential writes (fast!)
Data files are random writes (slow)
```

**fsync Trade-off:**
```
synchronous_commit = on (default):
â”œâ”€ Every commit waits for disk sync
â”œâ”€ Slow (5-10ms per commit)
â””â”€ Fully durable

synchronous_commit = off:
â”œâ”€ Commit returns immediately
â”œâ”€ Fast (0.1ms per commit)
â”œâ”€ Risk: Lose last few seconds if crash
â””â”€ Use: Acceptable data loss, high throughput

Group commit:
â”œâ”€ Batch multiple commits into one fsync
â”œâ”€ Amortize disk sync cost
â””â”€ Automatic in PostgreSQL, MySQL
```

### 1.2 Transactions

**Group multiple operations into atomic unit**

```sql
-- Basic transaction
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
COMMIT;  -- Or ROLLBACK to undo

-- Savepoints (partial rollback)
BEGIN;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
SAVEPOINT sp1;
UPDATE accounts SET balance = balance + 50 WHERE id = 2;
ROLLBACK TO sp1;  -- Undo second update only
UPDATE accounts SET balance = balance + 100 WHERE id = 3;
COMMIT;
```

**Distributed Transactions (2PC - Two-Phase Commit):**

```
Problem: Transaction spans multiple databases

Database A: Deduct $100 from Alice
Database B: Add $100 to Bob

How to ensure both or neither?

Two-Phase Commit:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: Prepare                            â”‚
â”‚ Coordinator â†’ DB A: "Can you commit?"       â”‚
â”‚ Coordinator â†’ DB B: "Can you commit?"       â”‚
â”‚ DB A â†’ "Yes" (ready to commit, locked)      â”‚
â”‚ DB B â†’ "Yes" (ready to commit, locked)      â”‚
â”‚                                             â”‚
â”‚ Phase 2: Commit                             â”‚
â”‚ Coordinator â†’ DB A: "Commit!"               â”‚
â”‚ Coordinator â†’ DB B: "Commit!"               â”‚
â”‚ DB A â†’ "Done"                               â”‚
â”‚ DB B â†’ "Done"                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

If any DB says "No" in phase 1:
â””â”€ Coordinator â†’ All DBs: "Abort!"

If coordinator crashes after phase 1:
â”œâ”€ DBs are blocked (waiting for decision)
â””â”€ Need timeout + coordinator recovery

Problem: Slow, blocking, not used at scale
Alternative: Saga pattern (compensating transactions)
```

### 1.3 Indexes

**Speed up queries by avoiding full table scans**

#### B-Tree Index (Default)

```
Without index:
SELECT * FROM users WHERE id = 12345;
â†’ Scan all 10M rows (slow, 5 seconds)

With index on id:
â†’ Traverse B-tree (fast, 0.001 seconds)

B-tree structure:
                [50|100]
               /    |    \
          [20|35] [70|80] [120|150]
         /  |  \   ...
    [1..19][20..34][35..49]

Each node: ~100s of keys
Tree height: log(N) â†’ 10M rows = 4-5 levels
Lookup: 4-5 disk reads (fast with caching)
```

**How B-tree works:**
```
Insert 42:
1. Start at root [50|100]
2. 42 < 50, go left to [20|35]
3. 35 < 42 < 50, go middle to [35..49]
4. Insert 42 in leaf node
5. If leaf full: Split node, propagate up

Delete 35:
1. Find 35 in tree
2. Remove from leaf
3. If leaf too empty: Merge with sibling

Update 20 â†’ 25:
1. Delete 20
2. Insert 25

Balanced tree: All leaves at same depth
```

**Creating Indexes:**
```sql
-- B-tree index (default, most common)
CREATE INDEX idx_users_email ON users(email);

-- Unique index (enforces uniqueness)
CREATE UNIQUE INDEX idx_users_username ON users(username);

-- Composite index (multiple columns)
CREATE INDEX idx_orders_user_date ON orders(user_id, created_at);
-- Helps queries: WHERE user_id = ? AND created_at > ?
-- Also helps: WHERE user_id = ? (leftmost prefix)
-- Doesn't help: WHERE created_at > ? (not leftmost)

-- Partial index (index subset)
CREATE INDEX idx_active_users ON users(email) WHERE active = true;
-- Smaller, faster for queries with WHERE active = true

-- Expression index
CREATE INDEX idx_users_lower_email ON users(LOWER(email));
-- Helps case-insensitive search: WHERE LOWER(email) = 'alice@example.com'
```

**Index Trade-offs:**
```
Pros:
+ Fast lookups (O(log N) vs O(N))
+ Fast sorting (ORDER BY)
+ Enforce uniqueness

Cons:
- Slower writes (update index on INSERT/UPDATE/DELETE)
- Extra disk space (50-100% of table size)
- Maintenance overhead (rebalancing)

Rule: Index columns in WHERE, JOIN, ORDER BY
Don't index: Low-cardinality (gender, boolean), rarely queried
```

#### Hash Index

```
Hash function: key â†’ bucket

users:
â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ id   â”‚ email     â”‚ bucket â”‚
â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1    â”‚ a@e.com   â”‚ h(a@)  â”‚ â†’ Bucket 42
â”‚ 2    â”‚ b@e.com   â”‚ h(b@)  â”‚ â†’ Bucket 17
â”‚ 3    â”‚ c@e.com   â”‚ h(c@)  â”‚ â†’ Bucket 42 (collision)
â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Lookup: O(1) average
Range query: Not supported (no ordering)

Use: Exact match only (WHERE email = 'a@e.com')
```

```sql
-- PostgreSQL
CREATE INDEX idx_users_email_hash ON users USING HASH(email);

-- Good for: WHERE email = ?
-- Bad for: WHERE email LIKE 'a%', WHERE email > 'a'
```

#### GiST/GIN Index (Full-Text, Arrays, JSON)

```sql
-- Full-text search (GIN)
CREATE INDEX idx_posts_search ON posts USING GIN(to_tsvector('english', content));

SELECT * FROM posts 
WHERE to_tsvector('english', content) @@ to_tsquery('database & performance');

-- Array index (GIN)
CREATE INDEX idx_posts_tags ON posts USING GIN(tags);

SELECT * FROM posts WHERE tags @> ARRAY['postgresql', 'indexing'];

-- JSON index (GIN)
CREATE INDEX idx_users_metadata ON users USING GIN(metadata jsonb_path_ops);

SELECT * FROM users WHERE metadata @> '{"country": "USA"}';
```

#### Covering Index

```sql
-- Query needs: id, email, name
-- Index contains: id, email, name (all columns needed)
CREATE INDEX idx_users_covering ON users(id, email, name);

SELECT id, email, name FROM users WHERE id = 123;
-- Index-only scan (no table access, faster!)

Without covering index:
1. Search index for id=123
2. Get row pointer
3. Read row from table (extra I/O)

With covering index:
1. Search index for id=123
2. All data in index (no table access!)
```

#### Index Maintenance

```sql
-- Analyze index usage
SELECT 
    schemaname, tablename, indexname, 
    idx_scan, idx_tup_read, idx_tup_fetch
FROM pg_stat_user_indexes
WHERE idx_scan = 0;  -- Unused indexes

-- Remove unused index
DROP INDEX idx_rarely_used;

-- Rebuild fragmented index
REINDEX INDEX idx_users_email;

-- Automatic: VACUUM (PostgreSQL)
-- Removes dead tuples, rebuilds indexes
```

### 1.4 Query Optimization

**EXPLAIN: See query execution plan**

```sql
EXPLAIN ANALYZE
SELECT u.name, o.total
FROM users u
JOIN orders o ON u.id = o.user_id
WHERE u.created_at > '2024-01-01'
ORDER BY o.total DESC
LIMIT 10;

Output:
Limit  (cost=1234.56..1234.58 rows=10)
  -> Sort  (cost=1234.56..1345.67 rows=5000)
    -> Hash Join  (cost=100.00..1000.00 rows=5000)
      Hash Cond: (o.user_id = u.id)
      -> Seq Scan on orders o  (cost=0.00..500.00 rows=50000)
      -> Hash  (cost=90.00..90.00 rows=1000)
        -> Index Scan on users u  (cost=0.00..90.00 rows=1000)
          Index Cond: (created_at > '2024-01-01')

Read bottom-up:
1. Index scan on users (using idx_users_created_at)
2. Sequential scan on orders (no index!)
3. Hash join (build hash table from users, probe with orders)
4. Sort by total
5. Limit to 10 rows

Cost: Estimated I/O (lower is better)
Rows: Estimated row count
```

**Scan Types:**
```
Sequential Scan:
â”œâ”€ Read entire table
â”œâ”€ Fast for small tables or when fetching most rows
â””â”€ Slow for large tables with selective WHERE

Index Scan:
â”œâ”€ Use index to find rows
â”œâ”€ Fast for selective queries
â””â”€ Slower if fetching many rows (random I/O)

Index-Only Scan:
â”œâ”€ All data in index (covering index)
â”œâ”€ Fastest (no table access)
â””â”€ Requires covering index

Bitmap Scan:
â”œâ”€ Use multiple indexes
â”œâ”€ Combine results (AND/OR)
â””â”€ More efficient than multiple index scans
```

**Optimization Techniques:**
```sql
-- 1. Add missing index
CREATE INDEX idx_orders_user_id ON orders(user_id);

-- 2. Use composite index for multi-column WHERE
CREATE INDEX idx_users_created_active ON users(created_at, active);

-- 3. Avoid functions in WHERE (breaks index)
-- Bad:
WHERE YEAR(created_at) = 2024
-- Good:
WHERE created_at >= '2024-01-01' AND created_at < '2025-01-01'

-- 4. Use LIMIT (don't fetch all rows)
SELECT * FROM users ORDER BY created_at DESC LIMIT 100;

-- 5. Avoid SELECT * (fetch only needed columns)
SELECT id, name FROM users;  -- Not SELECT *

-- 6. Use EXISTS instead of COUNT
-- Bad:
IF (SELECT COUNT(*) FROM users WHERE email = ?) > 0
-- Good:
IF EXISTS (SELECT 1 FROM users WHERE email = ?)

-- 7. Batch inserts
-- Bad: 1000 individual INSERTs
-- Good:
INSERT INTO users (name, email) VALUES 
  ('Alice', 'a@e.com'),
  ('Bob', 'b@e.com'),
  ...  -- 1000 rows
```

### 1.5 PostgreSQL vs MySQL

| Feature | PostgreSQL | MySQL (InnoDB) |
|---------|------------|----------------|
| **ACID** | Full ACID | Full ACID |
| **Default Isolation** | Read Committed | Repeatable Read |
| **MVCC** | Yes (better) | Yes |
| **Replication** | Streaming, logical | Binary log, GTID |
| **JSON** | JSONB (binary, indexed) | JSON (text) |
| **Full-Text** | Built-in (tsvector) | Built-in |
| **CTE (WITH)** | Yes, recursive | Yes (8.0+) |
| **Window Functions** | Yes | Yes (8.0+) |
| **Geospatial** | PostGIS (excellent) | Basic |
| **Performance** | Complex queries | Simple queries |
| **Use Case** | Analytics, complex | Web apps, simple OLTP |

---

## 2. NoSQL Databases

**Flexible schema, horizontal scalability, eventual consistency**

### 2.1 Key-Value Stores (Dynamo-style)

**Simple: key â†’ value, extremely fast**

**Examples:** DynamoDB, Redis, Riak

#### How It Works

```
Data model:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Key    â”‚ Value      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ user:1 â”‚ {name:...} â”‚
â”‚ user:2 â”‚ {name:...} â”‚
â”‚ sess:a â”‚ {data:...} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Operations:
GET user:1           â†’ Returns value
PUT user:1 {data}    â†’ Stores value
DELETE user:1        â†’ Removes key
```

#### Consistent Hashing (Distribution)

```
Problem: Distribute keys across N nodes

Hash ring (0 to 2^160):
              Node A (hash=40)
                  /
                 /
    Node C ----â—---- Ring
    (hash=200) |
               |
            Node B (hash=120)

Key placement:
key1 (hash=50)  â†’ Node B (next node clockwise)
key2 (hash=150) â†’ Node C
key3 (hash=250) â†’ Node A

Add node D (hash=180):
â”œâ”€ Only keys in range (120, 180) move to D
â”œâ”€ ~1/N keys rebalanced (minimal disruption)
â””â”€ Other keys unaffected

Remove node B:
â”œâ”€ Keys in range (40, 120) move to C
â””â”€ ~1/N keys rebalanced
```

**Virtual Nodes (Vnodes):**
```
Problem: Nodes not evenly distributed on ring

Solution: Each physical node gets many virtual nodes

Physical nodes: 3 (A, B, C)
Virtual nodes: 256 per physical node

Ring: [A1, B1, C1, A2, B2, C2, ..., A256, B256, C256]

Benefits:
+ Better load distribution
+ Easier rebalancing
+ Flexible weighting (powerful nodes get more vnodes)
```

#### Replication & Quorum

```
Replication factor (N) = 3:
Write key:user:123 â†’ Replicate to 3 nodes

Coordinator node:
1. Hash key â†’ Determine primary node
2. Primary + next 2 nodes = replica set
3. Write to all 3 nodes

Example:
key:user:123 (hash=100) â†’ Node B
Replica set: [B, C, A] (clockwise)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Write:                             â”‚
â”‚ Client â†’ Coordinator (any node)    â”‚
â”‚       â†’ Node B (primary)           â”‚
â”‚       â†’ Node C (replica 1)         â”‚
â”‚       â†’ Node A (replica 2)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Quorum Reads/Writes:**
```
R = Read quorum
W = Write quorum
N = Replication factor

Consistency guarantee: R + W > N

Example: N=3, W=2, R=2
Write: Wait for 2/3 nodes to ack (strong consistency)
Read: Read from 2/3 nodes, return latest (see latest write)

R + W = 2 + 2 = 4 > 3 âœ“ Guaranteed overlap

Tuning:
N=3, W=1, R=1: Fast, weak consistency
N=3, W=2, R=2: Balanced
N=3, W=3, R=1: Slow writes, fast reads

Use case:
â”œâ”€ W=1, R=1: Shopping cart (eventual ok)
â”œâ”€ W=2, R=2: User profile (balance)
â””â”€ W=3, R=1: Audit log (durability critical)
```

#### DynamoDB Specifics

```
Partition key: Determines partition (hash distribution)
Sort key (optional): Clustering within partition

Table: Users
â”œâ”€ Partition key: user_id (hash)
â”œâ”€ Sort key: timestamp (range)
â””â”€ Data: {name, email, ...}

Query patterns:
1. Get user: user_id = 123
2. Get user's recent activity: user_id = 123 AND timestamp > T

Single partition access (fast!)
```

**Global Secondary Index (GSI):**
```
Problem: Query by email (not partition key)

Solution: Create GSI
â”œâ”€ Partition key: email
â”œâ”€ Sort key: (none)
â””â”€ Separate table, eventually consistent

Query:
SELECT * FROM users WHERE email = 'alice@example.com'
â†’ Use GSI (fast)

Cost: Extra storage, write capacity
```

**Provisioned vs On-Demand:**
```
Provisioned:
â”œâ”€ Set RCU (read capacity units), WCU (write capacity units)
â”œâ”€ 1 RCU = 4KB strongly consistent read/sec
â”œâ”€ 1 WCU = 1KB write/sec
â””â”€ Cost: $0.00065/hr per WCU

On-Demand:
â”œâ”€ Auto-scales
â”œâ”€ Pay per request
â””â”€ Cost: $1.25 per million writes

Use provisioned for steady load, on-demand for spiky
```

### 2.2 Wide-Column Stores (Cassandra)

**Column families, massive scale, write-optimized**

**Examples:** Cassandra, HBase, ScyllaDB

#### Data Model

```
Keyspace (like database):
  â””â”€ Table (column family):
      â”œâ”€ Partition key (row key)
      â”œâ”€ Clustering columns (sort order within partition)
      â””â”€ Columns (values)

Example: Time-series sensor data
CREATE TABLE sensor_data (
    sensor_id UUID,         -- Partition key
    timestamp TIMESTAMP,    -- Clustering column
    temperature FLOAT,
    humidity FLOAT,
    PRIMARY KEY (sensor_id, timestamp)
);

Data layout:
Partition: sensor_id=abc123
â”œâ”€ timestamp=2024-01-01 10:00 â†’ temp=20.5, humidity=65
â”œâ”€ timestamp=2024-01-01 10:01 â†’ temp=20.6, humidity=66
â”œâ”€ timestamp=2024-01-01 10:02 â†’ temp=20.4, humidity=65
â””â”€ ...

All rows for sensor_id=abc123 stored together (fast range queries)
```

**Wide Row:**
```
Single partition can have millions of columns

User activity log:
Partition key: user_id
Clustering: action_timestamp
Columns: action_type, details

user:123 partition:
â”œâ”€ 2024-01-01 10:00 â†’ login
â”œâ”€ 2024-01-01 10:05 â†’ view_product
â”œâ”€ 2024-01-01 10:10 â†’ add_to_cart
â”œâ”€ ... (millions of actions)
â””â”€ 2024-12-31 23:59 â†’ logout

Efficient: All user's data in one partition (one disk seek)
```

#### Write Path (LSM Tree)

```
Log-Structured Merge Tree (write-optimized):

1. Write â†’ MemTable (in-memory, sorted)
2. MemTable full â†’ Flush to SSTable (on disk)
3. Multiple SSTables â†’ Compaction (merge, remove deletes)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Write:                                   â”‚
â”‚ 1. Append to CommitLog (WAL, sequential) â”‚
â”‚ 2. Write to MemTable (in-memory)         â”‚
â”‚ 3. Return (fast, ~1ms)                   â”‚
â”‚                                          â”‚
â”‚ Background:                              â”‚
â”‚ 4. MemTable full â†’ Flush to SSTable      â”‚
â”‚ 5. Compaction: Merge SSTables            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Advantages:
+ Very fast writes (sequential, in-memory)
+ No in-place updates (append-only)
+ Write throughput: 10K-100K writes/sec per node

Disadvantages:
- Read amplification (check multiple SSTables)
- Write amplification (compaction rewrites data)
```

**Read Path:**
```
Read key:
1. Check MemTable (in-memory)
2. Check RowCache (if enabled)
3. Check Bloom filters (which SSTables might have key?)
4. Check SSTables (on disk, may need multiple)
5. Merge results (different timestamps)
6. Return latest value

Bloom filter:
â”œâ”€ Probabilistic: "key definitely NOT in SSTable" or "maybe"
â”œâ”€ Saves disk reads
â””â”€ False positive ok (just extra read), false negative not possible
```

#### Tuning: Replication & Consistency

```
Replication factor (RF) = 3:
Data replicated to 3 nodes

Consistency levels:
ONE:   Wait for 1 node (fast, weak)
QUORUM: Wait for (RF/2)+1 nodes (balanced)
ALL:   Wait for all nodes (slow, strong)

Write: CL=QUORUM (2/3 nodes)
Read: CL=QUORUM (2/3 nodes)
â†’ Strong consistency (overlap guaranteed)

Write: CL=ONE (1/3 nodes)
Read: CL=ONE (1/3 nodes)
â†’ Eventual consistency (fastest)

Tuning:
â”œâ”€ Session store: CL=ONE (speed)
â”œâ”€ User profile: CL=QUORUM (balance)
â””â”€ Financial: CL=ALL (safety)
```

#### Use Cases

```
âœ“ Time-series data (IoT sensors, logs)
âœ“ Write-heavy workloads (billions of writes/day)
âœ“ Massive scale (petabytes, thousands of nodes)
âœ“ No single point of failure (peer-to-peer)

âœ— Complex queries (no joins)
âœ— Ad-hoc queries (must design schema for queries)
âœ— Strong consistency by default
```

### 2.3 Document Stores (MongoDB)

**JSON-like documents, flexible schema, rich queries**

**Examples:** MongoDB, CouchDB, RavenDB

#### Data Model

```json
Collection: users
Document:
{
  "_id": ObjectId("507f1f77bcf86cd799439011"),
  "name": "Alice",
  "email": "alice@example.com",
  "address": {
    "street": "123 Main St",
    "city": "NYC",
    "zip": "10001"
  },
  "tags": ["vip", "premium"],
  "orders": [
    {"id": 1, "total": 99.99},
    {"id": 2, "total": 149.99}
  ]
}

Flexible schema:
â”œâ”€ Different documents can have different fields
â”œâ”€ Nested objects (address)
â”œâ”€ Arrays (tags, orders)
â””â”€ No migrations needed
```

#### Queries

```javascript
// Find by field
db.users.find({ name: "Alice" })

// Nested field
db.users.find({ "address.city": "NYC" })

// Array contains
db.users.find({ tags: "vip" })

// Range query
db.users.find({ age: { $gte: 18, $lte: 65 } })

// Complex query (AND, OR)
db.users.find({
  $and: [
    { age: { $gte: 18 } },
    { $or: [
        { "address.city": "NYC" },
        { "address.city": "LA" }
      ]
    }
  ]
})

// Projection (select specific fields)
db.users.find(
  { "address.city": "NYC" },
  { name: 1, email: 1 }  // Only return name, email
)

// Aggregation pipeline
db.orders.aggregate([
  { $match: { status: "completed" } },
  { $group: { _id: "$user_id", total: { $sum: "$amount" } } },
  { $sort: { total: -1 } },
  { $limit: 10 }
])
// Top 10 users by total order amount
```

#### Indexes

```javascript
// Single field index
db.users.createIndex({ email: 1 })  // 1 = ascending

// Compound index
db.users.createIndex({ city: 1, age: -1 })

// Multikey index (array)
db.users.createIndex({ tags: 1 })
// Indexes each element in tags array

// Text index (full-text search)
db.articles.createIndex({ content: "text" })
db.articles.find({ $text: { $search: "mongodb indexing" } })

// Geospatial index
db.places.createIndex({ location: "2dsphere" })
db.places.find({
  location: {
    $near: {
      $geometry: { type: "Point", coordinates: [-73.9, 40.7] },
      $maxDistance: 5000  // 5km
    }
  }
})

// TTL index (auto-delete)
db.sessions.createIndex({ createdAt: 1 }, { expireAfterSeconds: 3600 })
// Delete documents 1 hour after createdAt
```

#### Replication (Replica Set)

```
Replica Set: 3 nodes (1 primary, 2 secondaries)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Primary (R/W)                           â”‚
â”‚    â”œâ”€â”€â”€ Oplog (operation log)          â”‚
â”‚    â”‚                                    â”‚
â”‚    â”œâ”€â”€> Secondary 1 (read-only)        â”‚
â”‚    â”‚       â””â”€ Replicates oplog         â”‚
â”‚    â”‚                                    â”‚
â”‚    â””â”€â”€> Secondary 2 (read-only)        â”‚
â”‚            â””â”€ Replicates oplog         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Write:
1. Client â†’ Primary
2. Primary â†’ Oplog (local log)
3. Primary â†’ Secondaries (async)
4. Return to client (before secondaries ack)

Primary failure:
1. Secondaries detect (heartbeat timeout)
2. Election (majority vote)
3. New primary elected
4. Clients reconnect to new primary

Recovery: ~10-30 seconds
```

**Write Concern:**
```javascript
// w=1: Wait for primary only (default, fast)
db.users.insertOne(doc, { writeConcern: { w: 1 } })

// w="majority": Wait for majority of nodes (safer)
db.users.insertOne(doc, { writeConcern: { w: "majority" } })

// w=3: Wait for all 3 nodes (slowest, safest)
db.users.insertOne(doc, { writeConcern: { w: 3 } })

// j=true: Wait for journal (durable)
db.users.insertOne(doc, { writeConcern: { w: 1, j: true } })
```

**Read Preference:**
```javascript
// primary: Read from primary only (strong consistency)
db.users.find().readPref("primary")

// primaryPreferred: Primary if available, else secondary
db.users.find().readPref("primaryPreferred")

// secondary: Read from secondary (reduce primary load)
db.users.find().readPref("secondary")

// nearest: Read from closest node (lowest latency)
db.users.find().readPref("nearest")
```

#### Sharding (Horizontal Scaling)

```
Shard: Subset of data

Collection: users (10M documents)
Shard by: user_id

Shard 1: user_id 0-3M
Shard 2: user_id 3M-6M
Shard 3: user_id 6M-10M

Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Client                                 â”‚
â”‚   â†“                                    â”‚
â”‚ mongos (router)                        â”‚
â”‚   â”œâ”€â”€> Shard 1 (replica set)          â”‚
â”‚   â”œâ”€â”€> Shard 2 (replica set)          â”‚
â”‚   â””â”€â”€> Shard 3 (replica set)          â”‚
â”‚                                        â”‚
â”‚ Config servers (metadata)              â”‚
â”‚   â””â”€ Shard key ranges                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Query routing:
Query: user_id=5M
mongos â†’ Config servers â†’ "Shard 2 has user_id 5M"
mongos â†’ Shard 2 â†’ Return result

Query: All users in NYC
mongos â†’ All shards (scatter-gather, slow!)
```

**Shard Key Selection:**
```
Good shard key:
âœ“ High cardinality (many unique values)
âœ“ Even distribution (no hot shards)
âœ“ Query pattern aligned (targeted queries)

Bad shard key:
âœ— Low cardinality (gender, boolean)
âœ— Monotonic (timestamp, auto-increment)
  â†’ All writes go to one shard (hot shard)

Examples:
âœ“ user_id (hash, even distribution)
âœ“ hashed(email) (even distribution)
âœ— created_at (monotonic, hot shard)
âœ— country (low cardinality, hot shards)
```

#### Use Cases

```
âœ“ Flexible schema (evolving data model)
âœ“ Rich queries (complex filters, aggregations)
âœ“ Document-centric (JSON APIs, CMS)
âœ“ Horizontal scaling (sharding)

âœ— Multi-document transactions (limited support)
âœ— Strong consistency (eventual by default)
âœ— Complex joins (not designed for)
```

### 2.4 Time-Series Databases

**Optimized for time-stamped data (metrics, logs, events)**

**Examples:** InfluxDB, TimescaleDB (PostgreSQL extension), Prometheus

#### Data Model

```
Measurement: cpu_usage
Tags (indexed): host, region, datacenter
Fields (values): usage_percent, cores
Timestamp: 2024-01-01 10:00:00

Example:
cpu_usage,host=server1,region=us-east usage_percent=75.5,cores=8 1704110400

Query:
SELECT mean(usage_percent) 
FROM cpu_usage 
WHERE host='server1' AND time > now() - 1h
GROUP BY time(5m)
```

#### Storage Optimization

```
Columnar storage:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Timestamp       â”‚ Host    â”‚ CPU%        â”‚
â”‚ 2024-01-01 10:00â”‚ server1 â”‚ 75.5        â”‚
â”‚ 2024-01-01 10:01â”‚ server1 â”‚ 76.2        â”‚
â”‚ 2024-01-01 10:02â”‚ server1 â”‚ 74.8        â”‚
â”‚ ...                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Stored as columns:
Timestamp: [2024-01-01 10:00, 10:01, 10:02, ...]
Host: [server1, server1, server1, ...]
CPU%: [75.5, 76.2, 74.8, ...]

Benefits:
+ Compression (adjacent values similar)
  CPU%: [75.5, 76.2, 74.8] â†’ Delta encoding [75.5, +0.7, -1.4]
+ Fast aggregation (read only needed column)
+ Smaller disk footprint (10-100Ã— compression)
```

**Downsampling:**
```
Original: 1-second resolution (86,400 points/day)
Downsampled:
â”œâ”€ Last 7 days: 1-minute resolution (10,080 points/week)
â”œâ”€ Last 30 days: 5-minute resolution (8,640 points/month)
â””â”€ Older: 1-hour resolution (720 points/month)

Storage: 100GB â†’ 10GB (90% reduction)
Queries: Faster (fewer points)
```

**Retention Policies:**
```
Automatically delete old data:

InfluxDB:
CREATE RETENTION POLICY "one_week" ON "mydb" 
  DURATION 7d 
  REPLICATION 1 
  DEFAULT

TimescaleDB:
SELECT add_retention_policy('metrics', INTERVAL '30 days');

Auto-delete: Data older than 30 days removed
```

#### Use Cases

```
âœ“ Metrics (CPU, memory, network)
âœ“ IoT sensor data (temperature, humidity)
âœ“ Application logs (request latency, errors)
âœ“ Financial tick data (stock prices)

âœ— Transactional data (orders, payments)
âœ— User profiles (not time-series)
```

---

## 3. Specialized Datastores

### 3.1 Graph Databases

**Nodes, edges, properties - optimized for relationships**

**Examples:** Neo4j, Amazon Neptune, JanusGraph

#### Data Model

```
Nodes: Users, Products
Edges: FOLLOWS, PURCHASED
Properties: name, age, price

Example: Social network
(Alice:User {name: "Alice"}) 
  -[:FOLLOWS]-> 
(Bob:User {name: "Bob"})
  -[:PURCHASED]->
(Product {name: "Laptop", price: 999})

Cypher query (Neo4j):
MATCH (a:User {name: "Alice"})-[:FOLLOWS]->(friend)
RETURN friend.name

Find all friends of Alice
```

**Graph Traversal:**
```
Query: Friends of friends (2 hops)

MATCH (a:User {name: "Alice"})-[:FOLLOWS*2]->(fof)
RETURN fof.name

1 hop: Alice â†’ Bob, Charlie
2 hops: Alice â†’ Bob â†’ David, Bob â†’ Eve
        Alice â†’ Charlie â†’ Frank

Efficient in graph DB (index-free adjacency)
Inefficient in SQL (multiple joins)
```

**Use Cases:**
```
âœ“ Social networks (friends, followers)
âœ“ Recommendation engines (similar users bought)
âœ“ Fraud detection (suspicious transaction patterns)
âœ“ Knowledge graphs (entities, relationships)

Example: Fraud detection
MATCH (user1:User)-[:SHARED_IP]->(ip:IP)<-[:SHARED_IP]-(user2:User)
WHERE user1.suspicious = true
RETURN user2

Find users sharing IP with suspicious users
```

### 3.2 NewSQL

**SQL + horizontal scalability + ACID**

**Examples:** CockroachDB, Google Spanner, YugabyteDB

#### How It Works

```
Traditional SQL: Single node (vertical scaling)
NoSQL: Distributed (horizontal scaling, eventual consistency)
NewSQL: Distributed + ACID (best of both worlds)

Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SQL Layer (query parsing, planning) â”‚
â”‚         â†“                            â”‚
â”‚ Transaction Layer (ACID)             â”‚
â”‚         â†“                            â”‚
â”‚ Distribution Layer (sharding)        â”‚
â”‚         â†“                            â”‚
â”‚ Storage Layer (replication)          â”‚
â”‚    â”œâ”€â”€> Node 1                       â”‚
â”‚    â”œâ”€â”€> Node 2                       â”‚
â”‚    â””â”€â”€> Node 3                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Distributed Transactions:**
```
Google Spanner: TrueTime (synchronized clocks)
â”œâ”€ GPS + atomic clocks in datacenters
â”œâ”€ Clock uncertainty: Â±7ms
â””â”€ Ensures global ordering of transactions

CockroachDB: Hybrid Logical Clock (HLC)
â”œâ”€ Combines physical time + logical counter
â”œâ”€ No special hardware needed
â””â”€ Causal consistency across nodes

Two-Phase Commit (2PC):
1. Prepare phase: All nodes vote
2. Commit phase: All nodes commit if unanimous

Slower than NoSQL, faster than traditional distributed DB
```

**Use Cases:**
```
âœ“ Need SQL + global scale (e.commerce, fintech)
âœ“ Strong consistency required (financial transactions)
âœ“ Replacing sharded PostgreSQL/MySQL

âœ— Ultra-low latency (<1ms)
âœ— Eventual consistency acceptable
```

### 3.3 OLAP Warehouses

**Analytics on massive datasets (batch queries)**

**OLTP vs OLAP:**
```
OLTP (Online Transaction Processing):
â”œâ”€ Row-oriented (PostgreSQL, MySQL)
â”œâ”€ Many small transactions (INSERT, UPDATE, SELECT by ID)
â”œâ”€ Normalized schema (3NF)
â”œâ”€ Millisecond latency
â””â”€ Example: User login, place order

OLAP (Online Analytical Processing):
â”œâ”€ Column-oriented (Snowflake, BigQuery, Redshift)
â”œâ”€ Few large queries (aggregations, scans)
â”œâ”€ Denormalized schema (star/snowflake schema)
â”œâ”€ Second/minute latency
â””â”€ Example: Monthly revenue, user churn analysis
```

**Examples:** Snowflake, Google BigQuery, Amazon Redshift, ClickHouse

#### Columnar Storage

```
Row-oriented (OLTP):
Row 1: [id=1, name=Alice, age=30, city=NYC]
Row 2: [id=2, name=Bob, age=25, city=LA]
Row 3: [id=3, name=Charlie, age=35, city=NYC]

Disk layout: Row1 | Row2 | Row3

Query: SELECT AVG(age) FROM users
â†’ Read all rows (slow, read unnecessary data)

Column-oriented (OLAP):
Column id: [1, 2, 3]
Column name: [Alice, Bob, Charlie]
Column age: [30, 25, 35]
Column city: [NYC, LA, NYC]

Disk layout: [1,2,3] | [Alice,Bob,Charlie] | [30,25,35] | [NYC,LA,NYC]

Query: SELECT AVG(age) FROM users
â†’ Read age column only (fast, skip other columns)

Compression:
city: [NYC, LA, NYC] â†’ Dictionary [NYC=0, LA=1] + [0, 1, 0]
      12 bytes â†’ 8 bytes (50% savings)
```

**Query Execution:**
```
Query: SELECT city, AVG(age) FROM users WHERE age > 25 GROUP BY city

1. Scan age column: [30, 25, 35]
2. Filter: age > 25 â†’ [true, false, true]
3. Scan city column: [NYC, LA, NYC] â†’ [NYC, _, NYC]
4. Group by city: {NYC: [30, 35]}
5. Aggregate: {NYC: AVG([30, 35]) = 32.5}
6. Return: NYC, 32.5

Only read age and city columns (fast!)
Parallel execution across nodes
```

**Use Cases:**
```
âœ“ Business intelligence (dashboards, reports)
âœ“ Data warehousing (historical data)
âœ“ Log analysis (petabytes of logs)
âœ“ ML feature engineering

âœ— Real-time updates (batch loading preferred)
âœ— OLTP workloads (slow for single-row lookups)
```

### 3.4 Vector Databases

**Store and search high-dimensional vectors (embeddings)**

**Examples:** Pinecone, Weaviate, Milvus, pgvector (PostgreSQL extension)

#### What Are Vectors?

```
Embedding: Text/image â†’ high-dimensional vector

Text: "machine learning" â†’ [0.2, -0.5, 0.8, ..., 0.1]  (768 dimensions)
Image: cat.jpg â†’ [0.1, 0.9, -0.3, ..., 0.7]  (512 dimensions)

Similar items have similar vectors (cosine similarity)

"machine learning" â†’ [0.2, -0.5, 0.8, ...]
"deep learning"    â†’ [0.3, -0.4, 0.7, ...]  â† Close!
"pizza recipe"     â†’ [0.9, 0.1, -0.9, ...]  â† Far
```

#### Similarity Search

```
Cosine similarity:
similarity = dot(v1, v2) / (norm(v1) * norm(v2))

Range: -1 (opposite) to +1 (identical)

Query: Find similar documents to "machine learning"
1. Encode query: [0.2, -0.5, 0.8, ...]
2. Compare with all vectors in DB
3. Return top K most similar

Example:
Query vector: [0.2, -0.5, 0.8]
Doc1: [0.3, -0.4, 0.7] â†’ similarity = 0.95 âœ“
Doc2: [0.9, 0.1, -0.9] â†’ similarity = 0.12
Doc3: [0.25, -0.48, 0.82] â†’ similarity = 0.98 âœ“ (most similar)

Return: Doc3, Doc1
```

#### Indexing (ANN - Approximate Nearest Neighbors)

```
Brute force: Compare with all N vectors (slow, O(N))

ANN algorithms (fast, approximate):

1. HNSW (Hierarchical Navigable Small World):
   â”œâ”€ Graph structure (layers)
   â”œâ”€ Fast search (O(log N))
   â””â”€ High recall (95%+ accuracy)

2. IVF (Inverted File Index):
   â”œâ”€ Cluster vectors into groups
   â”œâ”€ Search only relevant clusters
   â””â”€ Faster, lower recall

3. LSH (Locality-Sensitive Hashing):
   â”œâ”€ Hash similar vectors to same bucket
   â”œâ”€ Search only same bucket
   â””â”€ Very fast, lowest recall
```

**pgvector (PostgreSQL):**
```sql
-- Create table with vector column
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding VECTOR(768)  -- 768-dimensional vector
);

-- Create index (HNSW)
CREATE INDEX ON documents USING hnsw (embedding vector_cosine_ops);

-- Insert
INSERT INTO documents (content, embedding) VALUES 
('Machine learning tutorial', '[0.2, -0.5, 0.8, ...]');

-- Search (top 5 similar)
SELECT content, embedding <=> '[0.2, -0.5, 0.8, ...]' AS distance
FROM documents
ORDER BY distance
LIMIT 5;

-- <=> is cosine distance operator
```

**Use Cases:**
```
âœ“ Semantic search (find similar documents)
âœ“ Recommendation systems (similar products)
âœ“ Image search (find similar images)
âœ“ RAG (Retrieval-Augmented Generation for LLMs)

Example: RAG pipeline
1. User query: "How to optimize PostgreSQL?"
2. Encode query â†’ vector
3. Search vector DB â†’ Top 5 similar docs
4. Pass docs to LLM â†’ Generate answer
```

---

## Decision Matrix: Choosing a Datastore

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Need ACID + complex queries?                               â”‚
â”‚ â””â”€ Yes â†’ PostgreSQL / MySQL (Relational)                   â”‚
â”‚ â””â”€ No â†’ Continue                                           â”‚
â”‚                                                            â”‚
â”‚ Need horizontal scale + eventual consistency ok?          â”‚
â”‚ â””â”€ Yes â†’ Continue                                          â”‚
â”‚ â””â”€ No â†’ NewSQL (CockroachDB, Spanner)                     â”‚
â”‚                                                            â”‚
â”‚ Simple key-value access?                                   â”‚
â”‚ â””â”€ Yes â†’ DynamoDB, Redis (Key-Value)                      â”‚
â”‚ â””â”€ No â†’ Continue                                           â”‚
â”‚                                                            â”‚
â”‚ Time-series data (metrics, logs)?                         â”‚
â”‚ â””â”€ Yes â†’ InfluxDB, TimescaleDB (Time-Series)             â”‚
â”‚ â””â”€ No â†’ Continue                                           â”‚
â”‚                                                            â”‚
â”‚ Document-centric, flexible schema?                        â”‚
â”‚ â””â”€ Yes â†’ MongoDB (Document)                                â”‚
â”‚ â””â”€ No â†’ Continue                                           â”‚
â”‚                                                            â”‚
â”‚ Massive write throughput (billions/day)?                  â”‚
â”‚ â””â”€ Yes â†’ Cassandra (Wide-Column)                          â”‚
â”‚ â””â”€ No â†’ Continue                                           â”‚
â”‚                                                            â”‚
â”‚ Graph/relationship queries?                               â”‚
â”‚ â””â”€ Yes â†’ Neo4j (Graph)                                     â”‚
â”‚ â””â”€ No â†’ Continue                                           â”‚
â”‚                                                            â”‚
â”‚ Analytics on massive datasets (OLAP)?                     â”‚
â”‚ â””â”€ Yes â†’ Snowflake, BigQuery (OLAP)                       â”‚
â”‚ â””â”€ No â†’ Continue                                           â”‚
â”‚                                                            â”‚
â”‚ Vector/embedding search?                                  â”‚
â”‚ â””â”€ Yes â†’ Pinecone, pgvector (Vector)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Real-World Example: E-commerce System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PostgreSQL (Primary DB):                                 â”‚
â”‚ â”œâ”€ Users, products, orders (ACID critical)              â”‚
â”‚ â”œâ”€ Inventory (strong consistency)                       â”‚
â”‚ â””â”€ Payments (transactions required)                     â”‚
â”‚                                                          â”‚
â”‚ Redis (Cache):                                           â”‚
â”‚ â”œâ”€ Session store (fast access)                          â”‚
â”‚ â”œâ”€ Shopping cart (temporary data)                       â”‚
â”‚ â””â”€ Product catalog cache (reduce DB load)               â”‚
â”‚                                                          â”‚
â”‚ MongoDB (Catalog):                                       â”‚
â”‚ â”œâ”€ Product details (flexible schema)                    â”‚
â”‚ â”œâ”€ User reviews (nested documents)                      â”‚
â”‚ â””â”€ Search filters (complex queries)                     â”‚
â”‚                                                          â”‚
â”‚ Cassandra (Activity Log):                               â”‚
â”‚ â”œâ”€ User activity (billions of events)                   â”‚
â”‚ â”œâ”€ Click tracking (write-heavy)                         â”‚
â”‚ â””â”€ Audit trail (immutable log)                          â”‚
â”‚                                                          â”‚
â”‚ Elasticsearch (Search):                                 â”‚
â”‚ â”œâ”€ Product search (full-text)                           â”‚
â”‚ â”œâ”€ Autocomplete (faceted search)                        â”‚
â”‚ â””â”€ Filters (brand, price, rating)                       â”‚
â”‚                                                          â”‚
â”‚ Snowflake (Analytics):                                  â”‚
â”‚ â”œâ”€ Sales reports (aggregations)                         â”‚
â”‚ â”œâ”€ User behavior analysis (OLAP)                        â”‚
â”‚ â””â”€ Business intelligence (dashboards)                   â”‚
â”‚                                                          â”‚
â”‚ Pinecone (Recommendations):                             â”‚
â”‚ â”œâ”€ Product embeddings (vector search)                   â”‚
â”‚ â”œâ”€ Similar products (cosine similarity)                 â”‚
â”‚ â””â”€ Personalized recommendations (ML-powered)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Polyglot persistence: Use right tool for each job!
```

## Best Practices Summary

```
âœ“ Choose datastore based on access patterns, not familiarity
âœ“ Use relational (PostgreSQL) for structured, ACID-critical data
âœ“ Use NoSQL for scale, flexibility, specific access patterns
âœ“ Use caching (Redis) to reduce database load
âœ“ Use read replicas to scale reads
âœ“ Index appropriately (trade-off: query speed vs write speed)
âœ“ Monitor query performance (EXPLAIN, slow query log)
âœ“ Plan for growth (sharding, partitioning)
âœ“ Backup regularly (automated, tested restores)
âœ“ Use connection pooling (reduce connection overhead)
âœ“ Implement retry logic with exponential backoff
âœ— Don't use NoSQL for complex joins (use graph or denormalize)
âœ— Don't skip indexes (massive performance impact)
âœ— Don't ignore replication lag (eventual consistency issues)
âœ— Don't forget about operational complexity (monitoring, backups)
```

Complete datastore foundation for system design! ğŸ—„ï¸ğŸ“Š
