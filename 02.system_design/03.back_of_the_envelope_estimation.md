# Back-of-the-Envelope Estimation

## Foundation: Powers of Two & Time Units

### Memory Units
```
Bit (b)       = 0 or 1
Byte (B)      = 8 bits
Kilobyte (KB) = 1,024 bytes      â‰ˆ 10Â³  (1 thousand)
Megabyte (MB) = 1,024 KB         â‰ˆ 10â¶  (1 million)
Gigabyte (GB) = 1,024 MB         â‰ˆ 10â¹  (1 billion)
Terabyte (TB) = 1,024 GB         â‰ˆ 10Â¹Â² (1 trillion)
Petabyte (PB) = 1,024 TB         â‰ˆ 10Â¹âµ (1 quadrillion)

Quick conversions (approximate):
1 KB â‰ˆ 1,000 bytes     = 10Â³
1 MB â‰ˆ 1,000 KB        = 10â¶
1 GB â‰ˆ 1,000 MB        = 10â¹
1 TB â‰ˆ 1,000 GB        = 10Â¹Â²
1 PB â‰ˆ 1,000 TB        = 10Â¹âµ
```

### Time Units
```
1 nanosecond  (ns) = 10â»â¹ sec
1 microsecond (Î¼s) = 10â»â¶ sec = 1,000 ns
1 millisecond (ms) = 10â»Â³ sec = 1,000 Î¼s
1 second      (s)  = 1,000 ms

Seconds per day:
1 day = 24 hours Ã— 60 min Ã— 60 sec = 86,400 sec â‰ˆ 10âµ sec (100K)

Seconds per year:
1 year = 365 days Ã— 86,400 = 31,536,000 sec â‰ˆ 31.5M sec â‰ˆ Ï€ Ã— 10â·

Quick memory trick: 1 year â‰ˆ Ï€ Ã— 10â· seconds
```

### Latency Numbers Every Programmer Should Know

```
Operation                           Time (ns)    Time (human scale)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
L1 cache reference                  0.5 ns       0.5 sec
Branch mispredict                   5 ns         5 sec
L2 cache reference                  7 ns         7 sec
Mutex lock/unlock                   25 ns        25 sec
Main memory reference               100 ns       100 sec (1.7 min)
Compress 1KB with Snappy            10,000 ns    2.7 hours
Send 1KB over 1 Gbps network        10,000 ns    2.7 hours
SSD random read                     150,000 ns   1.7 days
Read 1MB sequentially from memory   250,000 ns   2.9 days
Round trip in same datacenter       500,000 ns   5.8 days
Read 1MB from SSD                   1,000,000 ns 11.6 days
Disk seek                           10,000,000 ns 4 months
Read 1MB from disk                  20,000,000 ns 7.7 months
Send packet CAâ†’Netherlandsâ†’CA       150,000,000 ns 4.8 years

Key takeaways:
â”œâ”€ Memory is fast (100 ns)
â”œâ”€ SSD is acceptable (150 Î¼s random, 1 ms sequential MB)
â”œâ”€ Disk is slow (10 ms seek, 20 ms per MB)
â”œâ”€ Network within DC is OK (0.5 ms)
â””â”€ Cross-continent is expensive (150 ms)
```

---

## 1. QPS (Queries Per Second) Calculation

### Formula & Conversions

```
QPS = Total Operations / Seconds

Conversions:
â”œâ”€ Per second  â†’ QPS (already QPS)
â”œâ”€ Per minute  â†’ QPS = ops/minute / 60
â”œâ”€ Per hour    â†’ QPS = ops/hour / 3,600
â”œâ”€ Per day     â†’ QPS = ops/day / 86,400 â‰ˆ ops/day / 10âµ
â””â”€ Per month   â†’ QPS = ops/month / 2,592,000 â‰ˆ ops/month / 2.6M

Quick approximation:
Daily QPS = Operations per day / 100,000
```

### Example 1: Social Media Platform

**Given:**
- 500M Daily Active Users (DAU)
- Each user:
  - Posts 2 updates/day
  - Views 100 posts/day
  - Likes 10 posts/day
  - Searches 3 times/day

**Calculate QPS:**

```
Write Operations (posts):
500M users Ã— 2 posts = 1B posts/day
QPS = 1,000,000,000 / 86,400 = 11,574 posts/sec â‰ˆ 12K writes/sec

Read Operations (views):
500M users Ã— 100 views = 50B views/day
QPS = 50,000,000,000 / 86,400 = 578,704 views/sec â‰ˆ 579K reads/sec

Like Operations:
500M users Ã— 10 likes = 5B likes/day
QPS = 5,000,000,000 / 86,400 = 57,870 likes/sec â‰ˆ 58K likes/sec

Search Operations:
500M users Ã— 3 searches = 1.5B searches/day
QPS = 1,500,000,000 / 86,400 = 17,361 searches/sec â‰ˆ 17K searches/sec

Total QPS: 12K + 579K + 58K + 17K = 666K QPS
Read:Write Ratio = 579K:12K â‰ˆ 48:1 (highly read-heavy)
```

### Example 2: E-commerce Site

**Given:**
- 10M DAU
- Each user:
  - Browses 20 products/day
  - Adds 2 items to cart/day
  - Searches 5 times/day
  - Completes 0.1 purchases/day (10% conversion over 10 days)

**Calculate QPS:**

```
Browse (reads):
10M Ã— 20 = 200M product views/day
QPS = 200,000,000 / 86,400 = 2,315 views/sec â‰ˆ 2.3K reads/sec

Add to cart (writes):
10M Ã— 2 = 20M cart additions/day
QPS = 20,000,000 / 86,400 = 231 adds/sec â‰ˆ 231 writes/sec

Search:
10M Ã— 5 = 50M searches/day
QPS = 50,000,000 / 86,400 = 579 searches/sec â‰ˆ 579 search QPS

Purchases (writes):
10M Ã— 0.1 = 1M purchases/day
QPS = 1,000,000 / 86,400 = 11.6 purchases/sec â‰ˆ 12 purchases/sec

Total QPS: 2,300 + 231 + 579 + 12 = 3,122 QPS â‰ˆ 3.1K QPS
```

---

## 2. Storage Per Day Calculation

### Data Size Estimation

#### Common Data Sizes

```
Type                Size          Example
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Character (ASCII)   1 byte        'A'
Character (UTF-8)   1-4 bytes     'ä¸–' = 3 bytes
Boolean             1 byte        true/false
Integer (32-bit)    4 bytes       123456
Long (64-bit)       8 bytes       User ID, timestamp
Float               4 bytes       3.14
Double              8 bytes       3.14159265359
UUID                16 bytes      550e8400-e29b-41d4...
Timestamp           8 bytes       Unix timestamp
IPv4 address        4 bytes       192.168.1.1
IPv6 address        16 bytes      2001:0db8:85a3...

Text content:
â”œâ”€ Tweet (280 chars)     ~300 bytes  (with metadata)
â”œâ”€ Email                 ~75 KB      (average)
â”œâ”€ Short article         ~10 KB
â””â”€ Book                  ~1-2 MB

Media:
â”œâ”€ Profile photo (thumb) ~50 KB
â”œâ”€ Full photo           ~500 KB - 2 MB
â”œâ”€ 4K photo             ~5-10 MB
â”œâ”€ MP3 song (3 min)     ~3 MB
â”œâ”€ Video (1 min, 720p)  ~10 MB
â”œâ”€ Video (1 min, 1080p) ~50 MB
â””â”€ Video (1 min, 4K)    ~200 MB
```

### Example 1: Twitter-like System

**Given:**
- 500M DAU
- Each user posts 2 tweets/day
- 10% of tweets have an image (avg 200 KB)
- 1% of tweets have a video (avg 2 MB)

**Calculate Storage/Day:**

```
Text tweets:
500M users Ã— 2 tweets = 1B tweets/day
Average tweet size:
â”œâ”€ Text (280 chars):          280 bytes
â”œâ”€ Metadata (user_id, etc):   200 bytes
â”œâ”€ Timestamp:                   8 bytes
â””â”€ Total:                     ~500 bytes = 0.5 KB

Text storage: 1B tweets Ã— 0.5 KB = 500 GB/day

Image tweets:
10% have images: 1B Ã— 0.1 = 100M images/day
Image storage: 100M Ã— 200 KB = 20 TB/day

Video tweets:
1% have videos: 1B Ã— 0.01 = 10M videos/day
Video storage: 10M Ã— 2 MB = 20 TB/day

Total storage/day:
â”œâ”€ Text:    0.5 TB
â”œâ”€ Images: 20 TB
â”œâ”€ Videos: 20 TB
â””â”€ Total:  40.5 TB/day

Per year: 40.5 TB Ã— 365 = 14,782 TB â‰ˆ 15 PB/year

With replication (3Ã—): 15 PB Ã— 3 = 45 PB/year
With backup (1Ã—):      15 PB Ã— 1 = 15 PB/year
Total needed:                      60 PB/year
```

### Example 2: Photo Sharing App (Instagram-like)

**Given:**
- 300M DAU
- Each user uploads 1 photo/day
- Each photo: 2 MB original
- Generate 3 thumbnails: 50 KB, 150 KB, 300 KB

**Calculate Storage/Day:**

```
Original photos:
300M users Ã— 1 photo = 300M photos/day
Storage: 300M Ã— 2 MB = 600 TB/day

Thumbnails:
300M photos Ã— (50 + 150 + 300) KB = 300M Ã— 500 KB = 150 TB/day

Metadata (per photo):
â”œâ”€ User ID:         8 bytes
â”œâ”€ Photo ID:        8 bytes
â”œâ”€ Timestamp:       8 bytes
â”œâ”€ Location:       16 bytes
â”œâ”€ Caption:       200 bytes
â”œâ”€ Tags:          100 bytes
â”œâ”€ Likes count:     4 bytes
â””â”€ Total:         344 bytes â‰ˆ 0.35 KB

Metadata storage: 300M Ã— 0.35 KB = 105 GB/day â‰ˆ 0.1 TB/day

Total storage/day:
â”œâ”€ Original:   600 TB
â”œâ”€ Thumbnails: 150 TB
â”œâ”€ Metadata:     0.1 TB
â””â”€ Total:      750.1 TB/day â‰ˆ 750 TB/day

Per year: 750 TB Ã— 365 = 273,750 TB â‰ˆ 274 PB/year

With replication (3Ã—): 274 Ã— 3 = 822 PB/year
With archival (1Ã—):    274 Ã— 1 = 274 PB/year
Total needed:                  1,096 PB â‰ˆ 1.1 EB/year
```

### Example 3: Video Streaming (YouTube-like)

**Given:**
- 100M videos uploaded/month
- Average video duration: 5 minutes
- Multiple qualities:
  - 360p: 5 MB/min
  - 720p: 15 MB/min
  - 1080p: 50 MB/min

**Calculate Storage/Month:**

```
Original uploads (assume 1080p):
100M videos Ã— 5 min Ã— 50 MB/min = 100M Ã— 250 MB = 25 PB/month

Transcoding to multiple qualities:
Per video storage:
â”œâ”€ 360p:  5 min Ã— 5 MB/min  = 25 MB
â”œâ”€ 720p:  5 min Ã— 15 MB/min = 75 MB
â”œâ”€ 1080p: 5 min Ã— 50 MB/min = 250 MB
â””â”€ Total:                     350 MB

Transcoded storage: 100M videos Ã— 350 MB = 35 PB/month

Metadata:
â”œâ”€ Video info, descriptions, tags: ~10 KB per video
â””â”€ Storage: 100M Ã— 10 KB = 1 TB/month (negligible)

Total storage/month: 25 PB (original) + 35 PB (transcoded) = 60 PB/month

Per year: 60 PB Ã— 12 = 720 PB/year

With replication (2Ã—): 720 Ã— 2 = 1,440 PB/year â‰ˆ 1.4 EB/year
```

---

## 3. Bandwidth Calculation

### Formula

```
Bandwidth = Data Size Ã— Frequency

Units:
â”œâ”€ bps  = bits per second
â”œâ”€ Kbps = kilobits per second (Ã— 1,000)
â”œâ”€ Mbps = megabits per second (Ã— 1,000,000)
â””â”€ Gbps = gigabits per second (Ã— 1,000,000,000)

Conversion:
Bytes to bits: multiply by 8
Example: 100 MB/sec = 100 Ã— 8 = 800 Mbps
```

### Example 1: Twitter-like System

**From previous calculation:**
- Writes: 12K tweets/sec
- Reads: 579K views/sec
- Average tweet: 0.5 KB (text only)
- 10% with images (200 KB)
- 1% with videos (2 MB)

**Calculate Bandwidth:**

```
Write bandwidth (upload):
Text: 12K tweets/sec Ã— 0.5 KB = 6 MB/sec
Images: 12K Ã— 0.1 Ã— 200 KB = 240 MB/sec
Videos: 12K Ã— 0.01 Ã— 2 MB = 240 MB/sec
Total upload: 6 + 240 + 240 = 486 MB/sec = 3.9 Gbps

Read bandwidth (download):
Text: 579K views/sec Ã— 0.5 KB = 289.5 MB/sec
Images: 579K Ã— 0.1 Ã— 200 KB = 11,580 MB/sec = 11.6 GB/sec
Videos: 579K Ã— 0.01 Ã— 2 MB = 11,580 MB/sec = 11.6 GB/sec
Total download: 0.29 + 11.6 + 11.6 = 23.5 GB/sec = 188 Gbps

Total bandwidth needed: 3.9 Gbps (up) + 188 Gbps (down) = 192 Gbps

Note: CDN would handle 90% of reads, reducing backend to ~19 Gbps
```

### Example 2: Video Streaming

**Given:**
- 10M concurrent viewers
- Average bitrate:
  - 360p: 0.5 Mbps
  - 720p: 2 Mbps
  - 1080p: 5 Mbps
- Distribution: 20% at 360p, 50% at 720p, 30% at 1080p

**Calculate Bandwidth:**

```
Concurrent viewers by quality:
â”œâ”€ 360p:  10M Ã— 0.2 = 2M viewers
â”œâ”€ 720p:  10M Ã— 0.5 = 5M viewers
â””â”€ 1080p: 10M Ã— 0.3 = 3M viewers

Bandwidth per quality:
â”œâ”€ 360p:  2M Ã— 0.5 Mbps = 1,000 Gbps = 1 Tbps
â”œâ”€ 720p:  5M Ã— 2 Mbps = 10,000 Gbps = 10 Tbps
â””â”€ 1080p: 3M Ã— 5 Mbps = 15,000 Gbps = 15 Tbps

Total bandwidth: 1 + 10 + 15 = 26 Tbps

Note: This is edge bandwidth (from CDN to users)
Origin servers need much less due to caching
```

### Example 3: File Sharing Service

**Given:**
- 1M file uploads/day (avg 10 MB)
- 10M file downloads/day (avg 10 MB)

**Calculate Bandwidth:**

```
Upload bandwidth:
1M uploads/day Ã— 10 MB = 10M MB/day = 10 TB/day
Per second: 10 TB / 86,400 = 115.7 MB/sec â‰ˆ 116 MB/sec = 928 Mbps â‰ˆ 1 Gbps

Download bandwidth:
10M downloads/day Ã— 10 MB = 100M MB/day = 100 TB/day
Per second: 100 TB / 86,400 = 1,157 MB/sec â‰ˆ 1.16 GB/sec = 9.3 Gbps â‰ˆ 10 Gbps

Total bandwidth: 1 Gbps (up) + 10 Gbps (down) = 11 Gbps

Peak (3Ã—): 11 Gbps Ã— 3 = 33 Gbps
```

---

## 4. Peak vs P95/P99 & Headroom

### Understanding Percentiles

```
Percentile = Value below which X% of data falls

Example: Response time for 1000 requests (sorted)
[10ms, 12ms, 15ms, ..., 100ms, 150ms, 500ms, 2000ms]

P50 (median): 50% of requests are faster than this value
P95: 95% of requests are faster (5% are slower)
P99: 99% of requests are faster (1% are slower)
P99.9: 99.9% of requests are faster (0.1% are slower)

Why P95/P99 matter:
â”œâ”€ Average doesn't show outliers
â”œâ”€ P95 = typical worst-case experience
â””â”€ P99 = worst experience for most users
```

### Traffic Patterns

```
             Average    Peak (3Ã—)    P95        P99
             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Social Media 100K QPS   300K QPS    250K QPS   280K QPS
E-commerce   10K QPS    100K QPS    40K QPS    80K QPS
  (normal)
E-commerce   10K QPS    500K QPS    200K QPS   400K QPS
  (Black Fri)

Key insight: Peak â‰  P99
â”œâ”€ Peak: Absolute maximum (brief spike)
â”œâ”€ P99: 99% of time, traffic is below this
â””â”€ Design for P99, not peak (cost-effective)
```

### Example: Social Media Feed

**Given:**
- Average QPS: 100K
- Daily traffic pattern:
  ```
  0-6am:   30K QPS  (30% of avg)
  6-9am:   80K QPS  (80%)
  9-12pm:  120K QPS (120%)
  12-2pm:  180K QPS (180%) â† lunch peak
  2-6pm:   100K QPS (100%)
  6-9pm:   200K QPS (200%) â† evening peak
  9-12am:  140K QPS (140%)
  ```

**Calculate Percentiles:**

```
Hourly QPS over 24 hours (sorted):
[30K, 30K, 30K, 30K, 30K, 30K,  â† 6 hours low
 80K, 80K, 80K,                 â† 3 hours morning
 100K, 100K, 100K, 100K,        â† 4 hours afternoon
 120K, 120K, 120K,              â† 3 hours midday
 140K, 140K, 140K,              â† 3 hours late night
 180K, 180K,                    â† 2 hours lunch
 200K, 200K, 200K]              â† 3 hours evening

P50 (12th value): 100K QPS
P95 (23rd value): 180K QPS  (95% of time â‰¤ 180K)
P99 (24th value): 200K QPS  (99% of time â‰¤ 200K)
Peak: 200K QPS

Design capacity: P99 Ã— 1.3 (30% headroom) = 200K Ã— 1.3 = 260K QPS
```

### Headroom Calculation

**Headroom** = Extra capacity beyond expected load

```
Purpose:
â”œâ”€ Handle unexpected spikes
â”œâ”€ Allow for growth
â”œâ”€ Provide buffer during failures
â””â”€ Maintain performance during deploys

Formula:
Design Capacity = Expected Load Ã— (1 + Headroom %)

Common headroom percentages:
â”œâ”€ 30% (1.3Ã—): Standard for stable traffic
â”œâ”€ 50% (1.5Ã—): Growing services
â”œâ”€ 100% (2Ã—): Unpredictable traffic
â””â”€ 200% (3Ã—): Critical services (payment)
```

### Example: Capacity Planning

**Given:**
- Current average: 50K QPS
- P99: 120K QPS
- Growth: 20% per quarter
- Target: Plan for next 12 months

**Calculate Required Capacity:**

```
Growth over 12 months:
Year 1 growth = (1.20)â´ â‰ˆ 2.07Ã— (4 quarters)

Expected P99 in 12 months:
120K QPS Ã— 2.07 = 248K QPS

With 30% headroom:
Design capacity = 248K Ã— 1.3 = 322K QPS â‰ˆ 320K QPS

Server capacity planning:
â”œâ”€ Each server: 2K QPS
â”œâ”€ Servers needed: 320K / 2K = 160 servers
â”œâ”€ With N+2 redundancy: 162 servers
â””â”€ Round up: 165 servers (3 zones Ã— 55 servers)

Cost estimation:
â”œâ”€ Per server: $200/month
â”œâ”€ 165 servers Ã— $200 = $33,000/month
â””â”€ Annual cost: $396,000/year
```

### Load Testing Strategy

```
Test levels:
1. Average load:       100K QPS  â† Normal operation
2. P95 load:           180K QPS  â† Daily peaks
3. P99 load:           200K QPS  â† Worst daily case
4. Design capacity:    260K QPS  â† With headroom
5. Breaking point:     300K+ QPS â† Find failure mode

Results:
â”œâ”€ At 100K: Response time 50ms (P95)
â”œâ”€ At 180K: Response time 80ms (P95)
â”œâ”€ At 200K: Response time 100ms (P95)
â”œâ”€ At 260K: Response time 150ms (P95) âœ“ Acceptable
â””â”€ At 300K: Response time 500ms (P95) âœ— System degraded

Conclusion: System can handle 260K QPS with good performance
```

---

## 5. RPS â†’ Instance Sizing

### RPS (Requests Per Second) per Instance

**Factors affecting RPS:**

```
1. Request complexity
   â”œâ”€ Simple: GET /health â†’ 10K RPS/instance
   â”œâ”€ Medium: GET /user/{id} (with cache) â†’ 2K RPS/instance
   â”œâ”€ Complex: POST /search (DB query) â†’ 200 RPS/instance
   â””â”€ Heavy: Video transcoding â†’ 10 RPS/instance

2. Instance size
   â”œâ”€ Small (2 CPU, 4GB RAM): 500 RPS
   â”œâ”€ Medium (4 CPU, 8GB RAM): 1500 RPS
   â””â”€ Large (8 CPU, 16GB RAM): 3000 RPS

3. Language/Framework
   â”œâ”€ Go/Rust: 3-5K RPS (compiled, efficient)
   â”œâ”€ Java/C#: 2-3K RPS (JVM, GC pauses)
   â”œâ”€ Node.js: 1-2K RPS (single-threaded, async)
   â””â”€ Python/Ruby: 200-500 RPS (interpreted, GIL)

4. I/O operations
   â”œâ”€ CPU-bound: Higher RPS (encryption, compression)
   â”œâ”€ Memory-bound: Medium RPS (caching, data processing)
   â”œâ”€ Network-bound: Lower RPS (API calls, DB queries)
   â””â”€ Disk-bound: Lowest RPS (file I/O)
```

### Instance Sizing Example

**Scenario: REST API for social media feed**

**Request profile:**
- 60% GET /feed (cached): 50ms avg, DB query on miss
- 30% POST /like: 20ms avg, DB write
- 10% POST /post: 100ms avg, DB write + fanout

**Benchmark results (4 CPU, 8GB instance):**
```
GET /feed:  2000 RPS (mostly cache hits)
POST /like: 1500 RPS (simple write)
POST /post: 300 RPS (complex operation)

Weighted average RPS:
(0.6 Ã— 2000) + (0.3 Ã— 1500) + (0.1 Ã— 300) = 1200 + 450 + 30 = 1680 RPS/instance
```

**Calculate instances needed:**

```
Target: 100K total RPS
Distribution:
â”œâ”€ GET /feed:  60K RPS
â”œâ”€ POST /like: 30K RPS
â””â”€ POST /post: 10K RPS

Method 1: Weighted average
Instances = 100K / 1680 = 59.5 â‰ˆ 60 instances

Method 2: By endpoint (if separate services)
â”œâ”€ Feed service:  60K / 2000 = 30 instances
â”œâ”€ Like service:  30K / 1500 = 20 instances
â””â”€ Post service:  10K / 300 = 33.3 â‰ˆ 34 instances
Total: 84 instances (more, but better isolation)

With 30% headroom:
Method 1: 60 Ã— 1.3 = 78 instances
Method 2: 84 Ã— 1.3 = 109 instances

Cost comparison:
Method 1: 78 Ã— $100/month = $7,800/month
Method 2: 109 Ã— $100/month = $10,900/month

Trade-off: 
â”œâ”€ Monolithic (Method 1): Cheaper, simpler
â””â”€ Microservices (Method 2): Better scaling, isolation
```

### Auto-scaling Configuration

```
Metric: CPU utilization
Target: 60% (leaving 40% headroom)

Scale-out (add instances):
â”œâ”€ Threshold: CPU > 70% for 5 minutes
â”œâ”€ Action: Add 20% more instances
â””â”€ Cooldown: 10 minutes

Scale-in (remove instances):
â”œâ”€ Threshold: CPU < 40% for 20 minutes
â”œâ”€ Action: Remove 10% of instances
â””â”€ Cooldown: 15 minutes

Min instances: 10 (always-on for availability)
Max instances: 200 (cost cap)

Example scaling:
Normal load (60K RPS):
â”œâ”€ Instances: 40
â””â”€ CPU: 60% (optimal)

Peak load (150K RPS):
â”œâ”€ CPU spikes to 75%
â”œâ”€ Auto-scale adds: 40 Ã— 0.2 = 8 instances
â””â”€ New total: 48 instances, CPU: 63%

Off-peak (20K RPS):
â”œâ”€ CPU drops to 35%
â”œâ”€ Auto-scale removes: 40 Ã— 0.1 = 4 instances
â””â”€ New total: 36 instances, CPU: 42%
```

---

## 6. Connection Limits

### TCP Connection Limits

```
OS limits (per server):
â”œâ”€ File descriptors: 65,536 (typical)
â”œâ”€ Ephemeral ports: 28,232 (16384-65536)
â””â”€ Can be increased: sysctl -w fs.file-max=1000000

Per connection memory:
â”œâ”€ Socket buffer: ~16 KB (8 KB send + 8 KB receive)
â”œâ”€ Connection object: ~4 KB
â””â”€ Total: ~20 KB per connection

Max connections (8 GB RAM server):
â”œâ”€ Available for connections: 4 GB (50% of total)
â”œâ”€ Per connection: 20 KB
â””â”€ Max: 4 GB / 20 KB = 204,800 connections

Practical limit: ~100K concurrent connections per server
(Leaving room for application memory)
```

### Database Connection Limits

```
PostgreSQL:
â”œâ”€ Default max connections: 100
â”œâ”€ Recommended: 200-500 per server
â””â”€ Can increase: max_connections = 500

MySQL:
â”œâ”€ Default max connections: 151
â”œâ”€ Recommended: 200-1000 per server
â””â”€ Can increase: max_connections = 1000

Connection pool sizing:
Formula: connections = ((core_count Ã— 2) + effective_spindle_count)

Example (4 CPU, 1 SSD):
connections = (4 Ã— 2) + 1 = 9 connections per app instance

Multiple app servers (10 servers):
Total connections = 10 Ã— 9 = 90 connections to DB
DB max_connections should be: 90 Ã— 1.3 = 117 (with buffer)
```

### Example: Connection Pool Configuration

**Scenario: Microservice with PostgreSQL**

**Given:**
- 50 app instances
- Each instance: 4 CPU cores
- PostgreSQL server: 16 CPU cores, 64 GB RAM

**Calculate Pool Size:**

```
Per instance pool size:
connections = (4 Ã— 2) + 1 = 9 connections

All instances total:
50 instances Ã— 9 = 450 connections

PostgreSQL configuration:
max_connections = 450 Ã— 1.2 = 540 (20% buffer)
shared_buffers = 16 GB (25% of RAM)
effective_cache_size = 48 GB (75% of RAM)

Connection breakdown:
â”œâ”€ App connections: 450
â”œâ”€ Monitoring: 10
â”œâ”€ Admin: 5
â”œâ”€ Replication: 5
â”œâ”€ Buffer: 70
â””â”€ Total: 540
```

### Load Balancer Limits

```
AWS Application Load Balancer (ALB):
â”œâ”€ Requests per second: 100,000+ (auto-scales)
â”œâ”€ Concurrent connections: 100,000+
â”œâ”€ New connections/sec: 10,000+
â””â”€ Targets: 1,000 per target group

NGINX:
â”œâ”€ Connections: 10,000 (default worker_connections)
â”œâ”€ Can increase to: 100,000+ (with tuning)
â””â”€ Worker processes: Set to CPU count

HAProxy:
â”œâ”€ Connections: 20,000 (default maxconn)
â”œâ”€ Can increase to: 1,000,000+ (with tuning)
â””â”€ Very efficient, low memory

Connection timeout:
â”œâ”€ Idle timeout: 60 seconds (default)
â”œâ”€ Keep-alive: 300 seconds (5 min)
â””â”€ Adjust based on use-case
```

---

## 7. File/Object Sizing

### Small Files vs Large Files

```
File Size       Count/TB    Strategy
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
< 1 KB          1B          Many small files, metadata overhead
1-100 KB        10M-1B      Typical: images, documents
100 KB-1 MB     1M-10M      Large images, small videos
1-100 MB        10K-1M      Videos, datasets
100 MB-1 GB     1K-10K      Large videos, backups
> 1 GB          < 1K        Huge files, rare
```

### Storage System Tradeoffs

#### Block Storage (EBS, SAN)
```
Best for: < 100 GB per file, frequent access
Performance: High (low latency, high IOPS)
Cost: High ($0.10-0.20/GB/month)
Use case: Databases, OS volumes

Sizing:
â”œâ”€ Small file (< 1 MB): 1 IOPS per file
â”œâ”€ Large file (> 1 MB): Sequential throughput
â””â”€ Provisioned IOPS: $0.065 per IOPS/month
```

#### Object Storage (S3, GCS, Azure Blob)
```
Best for: Any size, infrequent access
Performance: Medium (higher latency, high throughput)
Cost: Low ($0.02-0.05/GB/month)
Use case: Media, backups, archives

Pricing tiers (AWS S3):
â”œâ”€ Standard: $0.023/GB/month (frequent access)
â”œâ”€ Infrequent Access: $0.0125/GB/month (< 1 access/month)
â”œâ”€ Glacier: $0.004/GB/month (archive, retrieval in hours)
â””â”€ Deep Archive: $0.00099/GB/month (retrieval in 12 hours)

Additional costs:
â”œâ”€ PUT/POST: $0.005 per 1000 requests
â”œâ”€ GET: $0.0004 per 1000 requests
â””â”€ Data transfer out: $0.09/GB (first 10 TB)
```

#### File Storage (NFS, EFS)
```
Best for: Shared access, < 10 GB files
Performance: Medium (network latency)
Cost: Medium ($0.30/GB/month)
Use case: Shared configurations, logs

Sizing (AWS EFS):
â”œâ”€ Standard: $0.30/GB/month
â”œâ”€ Infrequent Access: $0.025/GB/month
â””â”€ Throughput: $6.00/MB/s/month (provisioned)
```

### File Sizing Strategy Example

**Scenario: Photo sharing app**

**Given:**
- 100M photos uploaded/month
- Distribution:
  - Thumbnails (50 KB): 100M Ã— 3 = 300M files
  - Medium (500 KB): 100M files
  - Original (5 MB): 100M files
- Access pattern:
  - Thumbnails: Hot (accessed daily)
  - Medium: Warm (accessed weekly)
  - Original: Cold (accessed rarely)

**Storage Calculation:**

```
Monthly storage:
â”œâ”€ Thumbnails: 300M Ã— 50 KB = 15 TB
â”œâ”€ Medium: 100M Ã— 500 KB = 50 TB
â””â”€ Original: 100M Ã— 5 MB = 500 TB
Total: 565 TB/month

Storage strategy:
1. Thumbnails (hot, small files):
   â”œâ”€ Location: S3 Standard + CloudFront CDN
   â”œâ”€ Cost: 15 TB Ã— $0.023 = $345/month
   â””â”€ CDN: $0.085/GB = 15,000 GB Ã— $0.085 = $1,275/month

2. Medium (warm):
   â”œâ”€ Location: S3 Standard
   â””â”€ Cost: 50 TB Ã— $0.023 = $1,150/month

3. Original (cold):
   â”œâ”€ Location: S3 Infrequent Access
   â””â”€ Cost: 500 TB Ã— $0.0125 = $6,250/month

Total storage cost: $345 + $1,150 + $6,250 = $7,745/month
CDN cost: $1,275/month
Total: $9,020/month

Per year: $9,020 Ã— 12 = $108,240/year

Year 1 cumulative storage: 565 TB Ã— 12 = 6,780 TB â‰ˆ 7 PB
```

### Chunking Large Files

**Why chunk?**
```
Benefits:
â”œâ”€ Parallel upload/download (faster)
â”œâ”€ Resume on failure (don't restart entire file)
â”œâ”€ Better error handling (retry single chunk)
â””â”€ Load distribution (across servers)

Chunk size guidelines:
â”œâ”€ Small files (< 10 MB): No chunking needed
â”œâ”€ Medium files (10-100 MB): 5 MB chunks
â”œâ”€ Large files (100 MB-1 GB): 10 MB chunks
â””â”€ Huge files (> 1 GB): 20-100 MB chunks
```

**Example: Upload 1 GB video**

```
Without chunking:
â”œâ”€ Single 1 GB upload
â”œâ”€ Time: 1 GB / 10 Mbps = 800 seconds â‰ˆ 13 minutes
â””â”€ If fails at 90%: Restart entire upload âŒ

With chunking (20 MB chunks):
â”œâ”€ 1 GB / 20 MB = 50 chunks
â”œâ”€ Parallel upload (5 threads): 13 min / 5 = 2.6 minutes
â”œâ”€ If 1 chunk fails: Retry only that 20 MB âœ“
â””â”€ Resume upload from any point âœ“

Implementation:
1. Client splits file into chunks
2. Client uploads chunks in parallel
3. Server stores chunks with metadata
4. Client sends "complete" request
5. Server assembles chunks (if needed) or marks complete

Metadata per upload:
{
  upload_id: "abc123",
  total_chunks: 50,
  chunk_size: 20971520,  // 20 MB
  uploaded_chunks: [1, 2, 3, ..., 50],
  complete: true
}
```

---

## 8. Cost Awareness

### Cloud Cost Components

```
1. Compute (40-50% of costs)
   â”œâ”€ EC2/VMs: On-demand, Reserved, Spot
   â”œâ”€ Serverless: Lambda/Functions
   â””â”€ Containers: ECS, EKS, GKE

2. Storage (20-30%)
   â”œâ”€ Block: EBS, Persistent Disks
   â”œâ”€ Object: S3, GCS, Azure Blob
   â””â”€ Database: RDS, DynamoDB, etc.

3. Network (10-20%)
   â”œâ”€ Data transfer out (expensive)
   â”œâ”€ Cross-region transfer
   â””â”€ Load balancer costs

4. Database (10-20%)
   â”œâ”€ RDS instances
   â”œâ”€ DynamoDB throughput
   â””â”€ Managed services

5. Other (5-10%)
   â”œâ”€ Monitoring, logs
   â”œâ”€ Backups
   â””â”€ Domain, certificates
```

### Cost Optimization Strategies

#### 1. Compute Optimization

```
Instance type selection:
â”œâ”€ General purpose: t3, t4 (burstable, cheaper for variable load)
â”œâ”€ Compute optimized: c5, c6 (for CPU-intensive)
â”œâ”€ Memory optimized: r5, r6 (for in-memory DBs, caching)
â””â”€ Storage optimized: i3, d2 (for data-intensive)

Pricing models:
1. On-demand:     $0.10/hour (flexible, expensive)
2. Reserved (1yr): $0.06/hour (40% savings, commitment)
3. Reserved (3yr): $0.04/hour (60% savings, long commitment)
4. Spot:          $0.03/hour (70% savings, can be terminated)

Example cost comparison (100 instances, 24/7):
â”œâ”€ On-demand:     $0.10 Ã— 24 Ã— 365 Ã— 100 = $876,000/year
â”œâ”€ Reserved (1yr): $0.06 Ã— 24 Ã— 365 Ã— 100 = $525,600/year (40% savings)
â””â”€ Mixed (50% Reserved, 30% Spot, 20% On-demand):
    ($0.06 Ã— 0.5 + $0.03 Ã— 0.3 + $0.10 Ã— 0.2) Ã— 24 Ã— 365 Ã— 100
    = $0.059 Ã— 876,000 = $516,840/year (41% savings)
```

#### 2. Storage Optimization

```
S3 Lifecycle policies:
Rule: Transition to cheaper tiers based on age

Example:
â”œâ”€ Day 0-30:     S3 Standard ($0.023/GB)
â”œâ”€ Day 31-90:    S3 IA ($0.0125/GB, -46%)
â”œâ”€ Day 91-365:   Glacier ($0.004/GB, -83%)
â””â”€ Day 365+:     Deep Archive ($0.00099/GB, -96%)

Cost for 100 TB over 2 years:
Without lifecycle:
100 TB Ã— $0.023 Ã— 24 months = $55,200

With lifecycle:
â”œâ”€ Months 1-1:   100 TB Ã— $0.023 Ã— 1 = $2,300
â”œâ”€ Months 2-3:   100 TB Ã— $0.0125 Ã— 2 = $2,500
â”œâ”€ Months 4-12:  100 TB Ã— $0.004 Ã— 9 = $3,600
â””â”€ Months 13-24: 100 TB Ã— $0.00099 Ã— 12 = $1,188
Total: $9,588 (83% savings!)
```

#### 3. Network Optimization

```
Data transfer costs (AWS):
â”œâ”€ In: Free
â”œâ”€ Between AZs: $0.01/GB
â”œâ”€ Between regions: $0.02/GB
â”œâ”€ Out to internet: $0.09/GB (first 10 TB)
â””â”€ CloudFront to internet: $0.085/GB (slightly cheaper)

Optimization strategies:
1. Use CDN (CloudFront) for static content
   â”œâ”€ Cache at edge: Reduces origin bandwidth
   â””â”€ Cheaper egress: $0.085 vs $0.09/GB

2. Keep traffic within same region
   â”œâ”€ Co-locate services: App + DB in same AZ
   â””â”€ Avoid cross-region: Unless necessary for DR

3. Compress data
   â”œâ”€ gzip: 70% reduction for text
   â””â”€ Brotli: 20% better than gzip

Example (1 PB/month egress):
Without optimization:
1000 TB Ã— $0.09 = $90,000/month

With CDN + compression:
â”œâ”€ 80% served from CDN: 800 TB Ã— $0.085 = $68,000
â”œâ”€ Compression (30% reduction): $68,000 Ã— 0.7 = $47,600
â”œâ”€ Origin (20%): 200 TB Ã— $0.09 = $18,000
â””â”€ Total: $47,600 + $18,000 = $65,600/month
Savings: $90,000 - $65,600 = $24,400/month (27% reduction)
```

#### 4. Database Optimization

```
RDS cost optimization:
1. Right-size instances
   â”œâ”€ Monitor CPU, memory, IOPS
   â””â”€ Downgrade if underutilized

2. Use read replicas (not multi-AZ) for reads
   â”œâ”€ Multi-AZ: 2Ã— cost, synchronous replication
   â””â”€ Read replica: 1Ã— cost each, async replication

3. Reserved instances
   â”œâ”€ 1-year: 35% savings
   â””â”€ 3-year: 60% savings

Example (PostgreSQL):
â”œâ”€ db.r5.4xlarge (on-demand): $2.05/hour
â”œâ”€ Reserved 1-year: $1.33/hour (35% off)
â”œâ”€ Reserved 3-year: $0.82/hour (60% off)
â””â”€ Annual: $2.05 Ã— 8760 = $17,958 vs $7,183 (60% savings)

Alternative: DynamoDB (NoSQL)
â”œâ”€ On-demand: $1.25/million write, $0.25/million read
â”œâ”€ Provisioned: $0.00065/write/hour, $0.00013/read/hour
â””â”€ Better for: Variable traffic, serverless apps
```

### Complete Cost Example: Social Media App

**Requirements:**
- 10M DAU
- 100M requests/day (10 req/user)
- 1,157 req/sec average, 3,500 req/sec peak
- 10 TB storage/month
- 50 TB bandwidth out/month

**Cost Breakdown:**

```
1. Compute (Application servers):
   â”œâ”€ Instance type: c5.xlarge (4 vCPU, 8 GB)
   â”œâ”€ Capacity: 2K req/sec per instance
   â”œâ”€ Instances needed: 3,500 / 2,000 = 1.75 â‰ˆ 2 instances (peak)
   â”œâ”€ With headroom (1.5Ã—): 3 instances
   â”œâ”€ Cost: 3 Ã— $0.17 Ã— 24 Ã— 30 = $367/month
   â””â”€ Reserved (1yr): $367 Ã— 0.65 = $239/month

2. Load Balancer:
   â”œâ”€ ALB: $22.50/month + $0.008 per LCU-hour
   â”œâ”€ LCU estimate: ~10 LCU
   â”œâ”€ Cost: $22.50 + (10 Ã— 24 Ã— 30 Ã— $0.008) = $80/month

3. Database (RDS PostgreSQL):
   â”œâ”€ Instance: db.r5.xlarge (4 vCPU, 32 GB)
   â”œâ”€ Primary: $0.42/hour Ã— 24 Ã— 30 = $302/month
   â”œâ”€ Read replica (2Ã—): $302 Ã— 2 = $604/month
   â”œâ”€ Storage: 500 GB Ã— $0.115 = $58/month
   â”œâ”€ Backup: 500 GB Ã— $0.095 = $48/month
   â””â”€ Total: $302 + $604 + $58 + $48 = $1,012/month

4. Cache (ElastiCache Redis):
   â”œâ”€ cache.r5.large (2 vCPU, 13 GB)
   â”œâ”€ Cost: $0.156 Ã— 24 Ã— 30 = $112/month
   â””â”€ Reserved (1yr): $112 Ã— 0.65 = $73/month

5. Storage (S3):
   â”œâ”€ Active data: 10 TB Ã— $0.023 = $230/month
   â”œâ”€ Archive (older): 20 TB Ã— $0.004 = $80/month
   â””â”€ Total: $310/month

6. CDN (CloudFront):
   â”œâ”€ Data transfer: 50 TB Ã— $0.085 = $4,250/month
   â””â”€ Requests: 100M/day Ã— 30 Ã— $0.0000001 = $300/month
   Total: $4,550/month

7. Monitoring & Logs:
   â”œâ”€ CloudWatch: $50/month
   â””â”€ Log storage: $30/month
   Total: $80/month

8. Data transfer (non-CDN):
   â””â”€ Minimal (CDN handles most): $100/month

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Monthly Total: $239 + $80 + $1,012 + $73 + $310 + $4,550 + $80 + $100
             = $6,444/month

Annual cost: $6,444 Ã— 12 = $77,328/year

Per user cost: $6,444 / 10M = $0.0006444/user/month = $0.0077/user/year

Cost breakdown by category:
â”œâ”€ CDN (71%):       $4,550
â”œâ”€ Database (16%):  $1,012
â”œâ”€ Storage (5%):    $310
â”œâ”€ Compute (4%):    $239
â”œâ”€ Monitoring (1%): $80
â””â”€ Other (3%):      $253
```

### Cost Monitoring & Alerts

```
Set up alerts for:
1. Daily spend > $300 (threshold based on budget)
2. Month-to-date projection > $10K
3. Sudden 20% increase in any service
4. Unused resources (idle instances, unattached volumes)

Cost optimization checklist:
â˜ Use Reserved Instances for steady workloads (40-60% savings)
â˜ Use Spot Instances for fault-tolerant workloads (70% savings)
â˜ Right-size instances (monitor CPU, memory)
â˜ Delete unused resources (old snapshots, volumes)
â˜ Use S3 lifecycle policies (move to cheaper tiers)
â˜ Enable CDN for static content (reduce bandwidth)
â˜ Compress data (reduce storage and bandwidth)
â˜ Use read replicas instead of multi-AZ (when possible)
â˜ Set up auto-scaling (scale down during off-peak)
â˜ Review and optimize monthly
```

---

## Quick Reference Card

### Key Formulas

```
QPS = Operations per day / 86,400
Storage per year = Daily storage Ã— 365
Bandwidth = Data size Ã— Operations per second Ã— 8 (to convert to Gbps)
Instances = Total QPS / RPS per instance Ã— (1 + headroom)
Cost = Resources Ã— Unit price Ã— Time

1 day = 86,400 seconds â‰ˆ 10âµ seconds
1 year = 31,536,000 seconds â‰ˆ Ï€ Ã— 10â· seconds
```

### Estimation Shortcuts

```
Powers of 10:
â”œâ”€ Thousand:    10Â³  = 1K
â”œâ”€ Million:     10â¶  = 1M
â”œâ”€ Billion:     10â¹  = 1B
â”œâ”€ Trillion:    10Â¹Â² = 1T
â””â”€ Quadrillion: 10Â¹âµ = 1Q

Memory:
â”œâ”€ KB = 10Â³ bytes
â”œâ”€ MB = 10â¶ bytes
â”œâ”€ GB = 10â¹ bytes
â”œâ”€ TB = 10Â¹Â² bytes
â””â”€ PB = 10Â¹âµ bytes

Typical sizes:
â”œâ”€ Tweet: 0.5 KB
â”œâ”€ Photo: 2 MB
â”œâ”€ Video (1 min): 50 MB
â””â”€ User record: 1 KB
```

### Capacity Planning Checklist

```
â˜ Calculate average QPS
â˜ Determine peak/P99 QPS (usually 2-3Ã— average)
â˜ Add 30-50% headroom
â˜ Calculate storage (per day, per year)
â˜ Include replication factor (3Ã— for critical data)
â˜ Calculate bandwidth (in and out)
â˜ Size instances (RPS per instance)
â˜ Estimate costs (compute + storage + network)
â˜ Plan for growth (20-30% per quarter)
â˜ Set up monitoring and alerts
```

---

## Practice Problems

### Problem 1: Design WhatsApp-like System

**Given:**
- 2B users worldwide
- 50% daily active (1B DAU)
- Each user sends 50 messages/day
- Average message: 100 bytes
- 5% messages have images (avg 500 KB)

**Calculate:**
1. Write QPS
2. Storage per day
3. Bandwidth
4. Instances needed (2K RPS per instance)

**Solution:**
```
1. Write QPS:
   1B users Ã— 50 messages = 50B messages/day
   QPS = 50B / 86,400 = 578,704 â‰ˆ 579K messages/sec

2. Storage per day:
   Text: 50B Ã— 100 bytes = 5 TB/day
   Images: 50B Ã— 0.05 Ã— 500 KB = 1,250 TB/day
   Total: 1,255 TB/day â‰ˆ 1.25 PB/day
   Per year: 1.25 PB Ã— 365 = 456 PB/year

3. Bandwidth (write only):
   Text: 579K msg/sec Ã— 100 bytes = 57.9 MB/sec â‰ˆ 463 Mbps
   Images: 579K Ã— 0.05 Ã— 500 KB = 14.475 GB/sec â‰ˆ 116 Gbps
   Total: 116 Gbps (upload)
   
4. Instances:
   With 30% headroom: 579K Ã— 1.3 = 753K QPS
   Instances: 753K / 2K = 376.5 â‰ˆ 377 instances
```

### Problem 2: Video Streaming Service

**Given:**
- 50M concurrent viewers
- Avg bitrate: 3 Mbps
- 100M videos uploaded/month
- Avg video: 10 minutes, 1080p (50 MB/min)

**Calculate:**
1. Bandwidth (viewer side)
2. Storage per month
3. CDN cost (at $0.085/GB)

**Solution:**
```
1. Bandwidth:
   50M viewers Ã— 3 Mbps = 150M Mbps = 150,000 Gbps = 150 Tbps

2. Storage per month:
   100M videos Ã— 10 min Ã— 50 MB/min = 100M Ã— 500 MB = 50 PB/month
   Per year: 50 PB Ã— 12 = 600 PB/year

3. CDN cost:
   Assume avg viewer watches 2 hours/day
   Daily transfer: 50M Ã— 2 hours Ã— 3 Mbps = 50M Ã— 7,200 sec Ã— 0.375 MB/sec
                 = 135,000 PB/day â‰ˆ 135 PB/day... wait, too high!
   
   Correction:
   Per viewer per day: 2 hours Ã— 3 Mbps = 7,200 sec Ã— 3 Mbits/sec = 21,600 Mbits = 2,700 MB = 2.7 GB
   All viewers: 50M Ã— 2.7 GB = 135M GB = 135 PB/day... still seems high
   
   Reality check: Not all 50M are concurrent 24/7
   If 50M concurrent peak, average might be 20M concurrent over 24 hours
   Total viewer-hours: 20M Ã— 24 = 480M hours/day
   Data: 480M hours Ã— 1.35 GB/hour = 648M GB/day = 648 TB/day
   
   Monthly: 648 TB Ã— 30 = 19,440 TB = 19.4 PB/month
   Cost: 19,440 TB Ã— $0.085 = $1,652,400/month = $19.8M/year
```

Perfect foundation for back-of-the-envelope calculations! ğŸš€

