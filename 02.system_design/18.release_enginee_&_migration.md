# Release Engineering & Migration

## What Is Release Engineering?

**Safe, automated deployment and migration of software**

```
Release engineering goals:
â”œâ”€ Fast deployment (minutes, not hours)
â”œâ”€ Zero downtime (no service interruption)
â”œâ”€ Easy rollback (revert if issues)
â”œâ”€ Gradual rollout (test on small traffic first)
â””â”€ Safe migrations (data changes without downtime)

Key practices:
1. CI/CD (Continuous Integration/Deployment)
2. Blue-Green deployment (instant switch)
3. Canary deployment (gradual rollout)
4. Feature flags (decouple deploy from release)
5. Schema migrations (database changes)
6. Data migrations (transform existing data)
7. Rollback strategies (undo changes safely)
```

---

## 1. CI/CD (Continuous Integration/Continuous Deployment)

### 1.1 Continuous Integration (CI)

**Automatically build and test every code change**

```
CI workflow:

1. Developer commits code â†’ Git repository
2. Webhook triggers CI pipeline
3. CI server:
   â”œâ”€ Checkout code
   â”œâ”€ Install dependencies
   â”œâ”€ Run linters (code quality)
   â”œâ”€ Run unit tests
   â”œâ”€ Run integration tests
   â”œâ”€ Build artifacts (Docker image, binaries)
   â””â”€ Push to registry (Docker Hub, Artifact Registry)
4. Success â†’ Ready for deployment
5. Failure â†’ Notify developer (email, Slack)

Benefits:
+ Catch bugs early (before production)
+ Fast feedback (minutes after commit)
+ Automated testing (no manual QA for basics)
+ Build once, deploy many (same artifact to dev/staging/prod)
```

**GitHub Actions CI Pipeline:**

```yaml
# .github/workflows/ci.yml
name: CI Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    # Checkout code
    - uses: actions/checkout@v3
    
    # Setup Python
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    # Install dependencies
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8
    
    # Lint code
    - name: Lint with flake8
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127
    
    # Run tests
    - name: Run tests
      run: |
        pytest --cov=app --cov-report=xml
    
    # Upload coverage
    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        files: ./coverage.xml
  
  build:
    runs-on: ubuntu-latest
    needs: test  # Only build if tests pass
    
    steps:
    - uses: actions/checkout@v3
    
    # Build Docker image
    - name: Build Docker image
      run: |
        docker build -t myapp:${{ github.sha }} .
    
    # Login to Docker Hub
    - name: Login to Docker Hub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
    
    # Push image
    - name: Push Docker image
      run: |
        docker tag myapp:${{ github.sha }} myusername/myapp:latest
        docker tag myapp:${{ github.sha }} myusername/myapp:${{ github.sha }}
        docker push myusername/myapp:latest
        docker push myusername/myapp:${{ github.sha }}
```

**GitLab CI Pipeline:**

```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy

variables:
  DOCKER_IMAGE: registry.gitlab.com/$CI_PROJECT_PATH

# Run tests
test:
  stage: test
  image: python:3.11
  script:
    - pip install -r requirements.txt
    - pip install pytest pytest-cov
    - pytest --cov=app
  coverage: '/TOTAL.*\s+(\d+%)$/'

# Build Docker image
build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - docker build -t $DOCKER_IMAGE:$CI_COMMIT_SHA .
    - docker tag $DOCKER_IMAGE:$CI_COMMIT_SHA $DOCKER_IMAGE:latest
    - docker push $DOCKER_IMAGE:$CI_COMMIT_SHA
    - docker push $DOCKER_IMAGE:latest
  only:
    - main

# Deploy to staging
deploy_staging:
  stage: deploy
  script:
    - kubectl set image deployment/myapp myapp=$DOCKER_IMAGE:$CI_COMMIT_SHA -n staging
  environment:
    name: staging
    url: https://staging.example.com
  only:
    - main

# Deploy to production (manual)
deploy_production:
  stage: deploy
  script:
    - kubectl set image deployment/myapp myapp=$DOCKER_IMAGE:$CI_COMMIT_SHA -n production
  environment:
    name: production
    url: https://example.com
  when: manual  # Require manual approval
  only:
    - main
```

### 1.2 Continuous Deployment (CD)

**Automatically deploy every passing build**

```
CD workflow:

1. CI pipeline passes
2. Deploy to staging (automatically)
3. Run smoke tests (basic health checks)
4. Deploy to production:
   â”œâ”€ Option A: Automatic (continuous deployment)
   â”œâ”€ Option B: Manual approval (continuous delivery)
   â””â”€ Option C: Gradual rollout (canary, blue-green)
5. Monitor metrics (errors, latency)
6. Rollback if needed (automatic or manual)

Continuous Delivery vs Continuous Deployment:
â”œâ”€ Continuous Delivery: Manual approval before production
â””â”€ Continuous Deployment: Fully automatic to production
```

**Kubernetes Deployment (CD):**

```bash
# deploy.sh (CD script)
#!/bin/bash

# Variables
IMAGE_TAG=$1
NAMESPACE="production"
DEPLOYMENT="myapp"

echo "Deploying $IMAGE_TAG to $NAMESPACE..."

# Update deployment image
kubectl set image deployment/$DEPLOYMENT \
  myapp=myusername/myapp:$IMAGE_TAG \
  -n $NAMESPACE

# Wait for rollout
kubectl rollout status deployment/$DEPLOYMENT -n $NAMESPACE

# Check if rollout succeeded
if [ $? -eq 0 ]; then
  echo "Deployment successful!"
else
  echo "Deployment failed, rolling back..."
  kubectl rollout undo deployment/$DEPLOYMENT -n $NAMESPACE
  exit 1
fi

# Run smoke tests
echo "Running smoke tests..."
curl -f https://api.example.com/health || {
  echo "Health check failed, rolling back..."
  kubectl rollout undo deployment/$DEPLOYMENT -n $NAMESPACE
  exit 1
}

echo "Deployment complete!"
```

---

## 2. Deployment Strategies

### 2.1 Blue-Green Deployment

**Two identical environments, instant switch**

```
Blue-Green deployment:

1. Current (Blue) environment serving traffic
2. Deploy new version (Green) environment
3. Test Green environment (smoke tests)
4. Switch traffic: Blue â†’ Green (instant)
5. Monitor Green environment
6. Rollback if issues: Green â†’ Blue (instant)
7. Decommission Blue environment (or keep for next release)

Architecture:

                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Load Balancerâ”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Blue (v1)    â”‚              â”‚  Green (v2)   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ App v1  â”‚  â”‚              â”‚  â”‚ App v2  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ DB v1   â”‚  â”‚              â”‚  â”‚ DB v2   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   (active)                      (standby)

Switch:
Blue: 100% traffic â†’ 0% traffic
Green: 0% traffic â†’ 100% traffic

Benefits:
+ Instant rollback (switch back to Blue)
+ Zero downtime (switch is instant)
+ Full testing before switch (Green is running)

Drawbacks:
- 2x resources (both environments running)
- Database migrations tricky (shared or duplicated?)
- Cost (double infrastructure)
```

**Blue-Green with Kubernetes:**

```yaml
# blue-deployment.yaml (current version)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-blue
  labels:
    app: myapp
    version: blue
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: blue
  template:
    metadata:
      labels:
        app: myapp
        version: blue
    spec:
      containers:
      - name: myapp
        image: myapp:v1
        ports:
        - containerPort: 5000

---
# green-deployment.yaml (new version)
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-green
  labels:
    app: myapp
    version: green
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: green
  template:
    metadata:
      labels:
        app: myapp
        version: green
    spec:
      containers:
      - name: myapp
        image: myapp:v2
        ports:
        - containerPort: 5000

---
# service.yaml (traffic routing)
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  selector:
    app: myapp
    version: blue  # Currently routing to Blue
  ports:
  - protocol: TCP
    port: 80
    targetPort: 5000
```

```bash
# Blue-Green deployment script

# 1. Deploy Green (new version)
kubectl apply -f green-deployment.yaml

# 2. Wait for Green to be ready
kubectl rollout status deployment/myapp-green

# 3. Test Green (internal)
kubectl port-forward deployment/myapp-green 8080:5000 &
curl http://localhost:8080/health

# 4. Switch traffic to Green
kubectl patch service myapp-service -p '{"spec":{"selector":{"version":"green"}}}'

# 5. Monitor metrics (errors, latency)
# If issues detected, rollback:
# kubectl patch service myapp-service -p '{"spec":{"selector":{"version":"blue"}}}'

# 6. Decommission Blue
kubectl delete deployment myapp-blue
```

### 2.2 Canary Deployment

**Gradual rollout to small percentage of users**

```
Canary deployment:

1. Deploy new version (canary) alongside old version
2. Route small traffic to canary (5%)
3. Monitor canary metrics (errors, latency)
4. Gradually increase canary traffic (5% â†’ 25% â†’ 50% â†’ 100%)
5. If issues, rollback (route 100% to old version)

Traffic split:

                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Load Balancerâ”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“ (95%)                     â†“ (5%)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stable (v1)  â”‚              â”‚  Canary (v2)  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ App v1  â”‚  â”‚              â”‚  â”‚ App v2  â”‚  â”‚
â”‚  â”‚ App v1  â”‚  â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚ App v1  â”‚  â”‚              â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚              â”‚                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Gradual rollout:
Step 1: 95% stable, 5% canary
Step 2: 75% stable, 25% canary
Step 3: 50% stable, 50% canary
Step 4: 0% stable, 100% canary (complete)

Benefits:
+ Low risk (small traffic first)
+ Gradual validation (monitor before full rollout)
+ Easy rollback (only 5% affected)

Drawbacks:
- Longer rollout (hours or days)
- More complex routing (traffic splitting)
- Two versions running simultaneously
```

**Canary with Kubernetes (Istio):**

```yaml
# stable-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-stable
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
      version: stable
  template:
    metadata:
      labels:
        app: myapp
        version: stable
    spec:
      containers:
      - name: myapp
        image: myapp:v1

---
# canary-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-canary
spec:
  replicas: 1  # Fewer replicas (less traffic)
  selector:
    matchLabels:
      app: myapp
      version: canary
  template:
    metadata:
      labels:
        app: myapp
        version: canary
    spec:
      containers:
      - name: myapp
        image: myapp:v2

---
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp
spec:
  selector:
    app: myapp  # Routes to both stable and canary
  ports:
  - port: 80
    targetPort: 5000

---
# virtual-service.yaml (Istio traffic split)
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: myapp
spec:
  hosts:
  - myapp
  http:
  - route:
    - destination:
        host: myapp
        subset: stable
      weight: 95  # 95% to stable
    - destination:
        host: myapp
        subset: canary
      weight: 5   # 5% to canary

---
# destination-rule.yaml (Istio subsets)
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: myapp
spec:
  host: myapp
  subsets:
  - name: stable
    labels:
      version: stable
  - name: canary
    labels:
      version: canary
```

```bash
# Canary deployment script

# 1. Deploy canary
kubectl apply -f canary-deployment.yaml

# 2. Start with 5% traffic
kubectl apply -f virtual-service-5.yaml

# 3. Monitor metrics (Prometheus, Grafana)
# Compare stable vs canary:
# - Error rate
# - Latency (p50, p95, p99)
# - Throughput

# 4. Gradual rollout (if metrics healthy)
sleep 3600  # Wait 1 hour
kubectl apply -f virtual-service-25.yaml  # 25% canary

sleep 3600
kubectl apply -f virtual-service-50.yaml  # 50% canary

sleep 3600
kubectl apply -f virtual-service-100.yaml  # 100% canary

# 5. Decommission stable
kubectl delete deployment myapp-stable

# Rollback (if issues detected)
# kubectl apply -f virtual-service-0.yaml  # 0% canary, 100% stable
```

**Automated Canary (Flagger):**

```yaml
# canary.yaml (Flagger)
apiVersion: flagger.app/v1beta1
kind: Canary
metadata:
  name: myapp
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  service:
    port: 80
  analysis:
    interval: 1m      # Check every minute
    threshold: 5      # Allow 5 failed checks before rollback
    maxWeight: 50     # Max 50% traffic to canary
    stepWeight: 10    # Increase by 10% each step
    metrics:
    - name: request-success-rate
      thresholdRange:
        min: 99       # Require 99% success rate
      interval: 1m
    - name: request-duration
      thresholdRange:
        max: 500      # Max 500ms latency (p99)
      interval: 1m
    webhooks:
    - name: load-test
      url: http://flagger-loadtester/
      timeout: 5s
      metadata:
        cmd: "hey -z 1m -q 10 -c 2 http://myapp/"

# Automatic rollout:
# 1. Deploy new version
# 2. Flagger automatically:
#    - Routes 10% traffic to canary
#    - Runs load tests
#    - Checks metrics (success rate, latency)
#    - If healthy, increases to 20%, 30%, ..., 50%
#    - If unhealthy, rolls back to stable
```

### 2.3 Feature Flags (Feature Toggles)

**Decouple deployment from release**

```
Feature flags:

Deploy code with feature disabled â†’ Enable feature for users later

Benefits:
+ Deploy anytime (feature not active)
+ Gradual rollout (enable for 5% users, then 100%)
+ A/B testing (compare old vs new feature)
+ Kill switch (disable feature if issues)
+ Trunk-based development (no long-lived branches)

Types:
1. Release toggles (temporary, enable new feature)
2. Experiment toggles (A/B testing, long-term)
3. Ops toggles (circuit breaker, disable service)
4. Permission toggles (premium features, user roles)
```

**Feature Flag Implementation:**

```python
# Simple feature flags (in-memory)
FEATURE_FLAGS = {
    'new_checkout_flow': False,
    'recommendation_engine': True,
    'dark_mode': False
}

def is_feature_enabled(feature_name, user_id=None):
    """Check if feature is enabled"""
    if feature_name not in FEATURE_FLAGS:
        return False
    
    flag = FEATURE_FLAGS[feature_name]
    
    # Simple on/off
    if isinstance(flag, bool):
        return flag
    
    # Percentage rollout (e.g., enable for 10% of users)
    if isinstance(flag, dict) and 'percentage' in flag:
        # Hash user_id to deterministic bucket (0-99)
        bucket = hash(user_id) % 100
        return bucket < flag['percentage']
    
    return False

# Usage
@app.route('/checkout')
def checkout():
    user_id = get_current_user_id()
    
    if is_feature_enabled('new_checkout_flow', user_id):
        # New checkout implementation
        return render_template('checkout_v2.html')
    else:
        # Old checkout implementation
        return render_template('checkout_v1.html')

# Percentage rollout
FEATURE_FLAGS['new_checkout_flow'] = {'percentage': 10}  # 10% of users

# Gradual rollout
# Day 1: 10%
# Day 2: 25%
# Day 3: 50%
# Day 4: 100%
```

**Feature Flags with LaunchDarkly:**

```python
import ldclient
from ldclient.config import Config

# Initialize LaunchDarkly
ldclient.set_config(Config("your-sdk-key"))
ld_client = ldclient.get()

@app.route('/checkout')
def checkout():
    user = {
        'key': get_current_user_id(),
        'email': get_current_user_email(),
        'custom': {
            'plan': 'premium',
            'country': 'US'
        }
    }
    
    # Check feature flag (remote, real-time)
    use_new_checkout = ld_client.variation('new-checkout-flow', user, False)
    
    if use_new_checkout:
        return render_template('checkout_v2.html')
    else:
        return render_template('checkout_v1.html')

# LaunchDarkly dashboard:
# - Enable for specific users (email, user_id)
# - Enable for percentage (10%, 50%, 100%)
# - Enable for user attributes (plan=premium, country=US)
# - Schedule rollout (enable on specific date/time)
# - Kill switch (disable immediately)
```

**Feature Flag Best Practices:**

```python
# 1. Default to off (safe fallback)
def is_feature_enabled(feature_name, user_id=None, default=False):
    try:
        return ld_client.variation(feature_name, user_id, default)
    except:
        return default  # Fallback if LaunchDarkly unavailable

# 2. Clean up old flags (technical debt)
# Remove flags after full rollout (100%)

# Before:
if is_feature_enabled('new_checkout_flow'):
    return new_checkout()
else:
    return old_checkout()

# After (flag at 100% for 2 weeks, no issues):
return new_checkout()
# Delete old_checkout() code

# 3. Feature flag inventory (track active flags)
# - Feature name
# - Created date
# - Owner
# - Rollout percentage
# - Removal date (when to clean up)
```

---

## 3. Schema & Data Migrations

### 3.1 Schema Migrations

**Change database schema without downtime**

```
Schema migration challenge:

Old code expects old schema
New code expects new schema
Can't deploy both simultaneously (rolling deployment)

Solution: Backward-compatible migrations

Migration stages:
1. Add new schema (compatible with old code)
2. Deploy new code (uses new schema)
3. Remove old schema (old code no longer running)
```

**Example: Add Column (Backward Compatible)**

```sql
-- Stage 1: Add column (nullable, with default)
ALTER TABLE users
ADD COLUMN phone VARCHAR(20) DEFAULT NULL;

-- Old code still works (ignores new column)
-- New code can use new column

-- Stage 2: Deploy new code
-- New code reads/writes phone column

-- Stage 3: Make column NOT NULL (after backfill)
ALTER TABLE users
ALTER COLUMN phone SET NOT NULL;
```

**Example: Rename Column (3-Stage Migration)**

```sql
-- Current schema:
-- users (id, email, name)

-- Stage 1: Add new column
ALTER TABLE users
ADD COLUMN full_name VARCHAR(100);

-- Deploy code that writes to both columns
UPDATE users SET full_name = name WHERE full_name IS NULL;

-- Stage 2: Backfill old data
UPDATE users SET full_name = name WHERE full_name IS NULL;

-- Deploy code that reads from new column, writes to both
# app.py
def create_user(email, name):
    db.execute(
        "INSERT INTO users (email, name, full_name) VALUES (%s, %s, %s)",
        (email, name, name)  # Write to both
    )

# Stage 3: Remove old column
ALTER TABLE users DROP COLUMN name;

# Deploy code that only uses new column
```

**Migration Tools (Alembic for Python):**

```python
# migrations/versions/001_add_phone_column.py
from alembic import op
import sqlalchemy as sa

def upgrade():
    """Add phone column"""
    op.add_column('users',
        sa.Column('phone', sa.String(20), nullable=True)
    )

def downgrade():
    """Rollback: Remove phone column"""
    op.drop_column('users', 'phone')

# Run migration
# alembic upgrade head

# Rollback migration
# alembic downgrade -1
```

**Migration Best Practices:**

```python
# 1. Always reversible (downgrade)
def upgrade():
    op.add_column('users', sa.Column('age', sa.Integer, nullable=True))

def downgrade():
    op.drop_column('users', 'age')

# 2. Backward compatible (old code still works)
# âœ“ Add nullable column
# âœ“ Add table (not used by old code)
# âœ— Drop column (breaks old code)
# âœ— Rename column (breaks old code)

# 3. Small migrations (one change per migration)
# âœ“ Migration 001: Add column
# âœ“ Migration 002: Add index
# âœ— Migration 001: Add column, rename table, add index (too much)

# 4. Test migrations (staging environment)
# - Run migration on staging
# - Deploy new code to staging
# - Test application
# - Run migration on production

# 5. Lock-free migrations (avoid table locks)
# Bad (locks table during index creation):
CREATE INDEX idx_email ON users(email);

# Good (concurrent index, no lock):
CREATE INDEX CONCURRENTLY idx_email ON users(email);
```

### 3.2 Data Migrations

**Transform existing data**

```
Data migration: Change data format, structure, or location

Examples:
â”œâ”€ Backfill new column (populate existing rows)
â”œâ”€ Migrate to new table (move data)
â”œâ”€ Change data format (JSON â†’ separate columns)
â””â”€ Migrate to new database (MySQL â†’ PostgreSQL)

Strategies:
1. Backfill (batch update existing data)
2. Dual-writes (write to old and new simultaneously)
3. Shadow reads (read from new, compare with old)
4. Cutover (switch from old to new)
```

### 3.3 Backfills

**Populate new column for existing rows**

```
Backfill challenge:
â”œâ”€ Millions of existing rows
â”œâ”€ Can't update all at once (slow, locks table)
â””â”€ Need to update in batches (avoid downtime)

Backfill strategy:
1. Add new column (nullable)
2. Deploy code that writes to new column (new rows)
3. Backfill existing rows (batch updates)
4. Make column NOT NULL (after backfill complete)
```

**Backfill Example:**

```python
# Backfill phone column (from email domain)
def backfill_phone():
    batch_size = 1000
    offset = 0
    
    while True:
        # Fetch batch of users without phone
        users = db.execute(
            "SELECT id FROM users WHERE phone IS NULL LIMIT %s OFFSET %s",
            (batch_size, offset)
        ).fetchall()
        
        if not users:
            break  # No more users
        
        # Update batch
        for user in users:
            phone = generate_phone(user['id'])  # Generate phone from user_id
            db.execute(
                "UPDATE users SET phone = %s WHERE id = %s",
                (phone, user['id'])
            )
        
        db.commit()
        offset += batch_size
        
        print(f"Backfilled {offset} users...")
        time.sleep(1)  # Avoid overloading database

# Run backfill (background job)
# python backfill_phone.py
```

**Incremental Backfill (Idempotent):**

```python
# Backfill user_id column from UUID
def backfill_user_id():
    """Idempotent backfill (safe to re-run)"""
    
    # Track progress
    last_id = redis.get('backfill:last_id') or 0
    
    while True:
        # Fetch batch (start from last_id)
        users = db.execute(
            "SELECT id, uuid FROM users WHERE id > %s AND user_id IS NULL LIMIT 1000",
            (last_id,)
        ).fetchall()
        
        if not users:
            print("Backfill complete!")
            break
        
        # Update batch
        for user in users:
            user_id = hash_uuid(user['uuid'])
            db.execute(
                "UPDATE users SET user_id = %s WHERE id = %s",
                (user_id, user['id'])
            )
            last_id = user['id']
        
        db.commit()
        
        # Save progress (can resume if script crashes)
        redis.set('backfill:last_id', last_id)
        
        print(f"Backfilled up to ID {last_id}...")
        time.sleep(1)
```

### 3.4 Dual-Writes

**Write to old and new systems simultaneously**

```
Dual-writes: Migration strategy for live data

Stages:
1. Write to old system only (current state)
2. Write to old + new systems (dual-write)
3. Backfill old data to new system
4. Read from new system (verify)
5. Write to new system only (cutover)
6. Decommission old system

Example: Migrate from MySQL to PostgreSQL

           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   App    â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“    â†“
        â”Œâ”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”
        â†“                â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ MySQL  â”‚      â”‚PostgreSQLâ”‚
   â”‚ (old)  â”‚      â”‚  (new)   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   
Dual-write period: Write to both, read from old
```

**Dual-Write Example:**

```python
# Stage 1: Write to old DB only
def create_user(email, name):
    mysql_db.execute(
        "INSERT INTO users (email, name) VALUES (%s, %s)",
        (email, name)
    )

# Stage 2: Write to both (dual-write)
def create_user(email, name):
    # Write to old DB (primary)
    mysql_db.execute(
        "INSERT INTO users (email, name) VALUES (%s, %s)",
        (email, name)
    )
    mysql_db.commit()
    
    # Write to new DB (asynchronously, best-effort)
    try:
        postgres_db.execute(
            "INSERT INTO users (email, name) VALUES (%s, %s)",
            (email, name)
        )
        postgres_db.commit()
    except Exception as e:
        # Log error, don't fail request
        logger.error(f"Dual-write failed: {e}")

# Stage 3: Backfill old data to new DB
def backfill_to_postgres():
    offset = 0
    batch_size = 1000
    
    while True:
        users = mysql_db.execute(
            "SELECT * FROM users LIMIT %s OFFSET %s",
            (batch_size, offset)
        ).fetchall()
        
        if not users:
            break
        
        for user in users:
            postgres_db.execute(
                "INSERT INTO users (id, email, name) VALUES (%s, %s, %s) ON CONFLICT DO NOTHING",
                (user['id'], user['email'], user['name'])
            )
        
        postgres_db.commit()
        offset += batch_size

# Stage 4: Read from new DB (verify)
def get_user(user_id):
    # Read from new DB
    user = postgres_db.execute(
        "SELECT * FROM users WHERE id = %s",
        (user_id,)
    ).fetchone()
    
    # Shadow read: Compare with old DB (verify consistency)
    old_user = mysql_db.execute(
        "SELECT * FROM users WHERE id = %s",
        (user_id,)
    ).fetchone()
    
    if user != old_user:
        logger.error(f"Data inconsistency for user {user_id}")
    
    return user

# Stage 5: Write to new DB only (cutover)
def create_user(email, name):
    postgres_db.execute(
        "INSERT INTO users (email, name) VALUES (%s, %s)",
        (email, name)
    )
    postgres_db.commit()

# Stage 6: Decommission old DB
# Stop writing to MySQL
# Drop MySQL database
```

### 3.5 Shadow Reads

**Read from new system, compare with old (verification)**

```
Shadow reads: Verify new system correctness

Flow:
1. Read from old system (return to user)
2. Read from new system (shadow read)
3. Compare results (log differences)
4. Monitor discrepancies (fix bugs)
5. Switch to new system (once verified)

Benefits:
+ Verify correctness (before cutover)
+ Find bugs early (production traffic)
+ No user impact (shadow reads invisible)
```

**Shadow Read Example:**

```python
def get_user(user_id):
    # Primary read (old system)
    old_user = mysql_db.execute(
        "SELECT * FROM users WHERE id = %s",
        (user_id,)
    ).fetchone()
    
    # Shadow read (new system, asynchronous)
    async_shadow_read(user_id, old_user)
    
    # Return old user (no impact on user)
    return old_user

def async_shadow_read(user_id, expected_user):
    """Background shadow read"""
    try:
        # Read from new system
        new_user = postgres_db.execute(
            "SELECT * FROM users WHERE id = %s",
            (user_id,)
        ).fetchone()
        
        # Compare results
        if new_user != expected_user:
            logger.error(f"Shadow read mismatch for user {user_id}: {new_user} vs {expected_user}")
            metrics.increment('shadow_read.mismatch')
        else:
            metrics.increment('shadow_read.match')
    except Exception as e:
        logger.error(f"Shadow read failed: {e}")
        metrics.increment('shadow_read.error')
```

### 3.6 Rollback Plans

**Undo changes safely**

```
Rollback strategies:

1. Code rollback:
   â”œâ”€ Revert to previous deployment
   â”œâ”€ Blue-green: Switch back to Blue
   â””â”€ Canary: Route 0% to canary

2. Database rollback:
   â”œâ”€ Run downgrade migration (reverse schema change)
   â”œâ”€ Restore from backup (data loss risk)
   â””â”€ Dual-write: Switch back to old system

3. Feature flag rollback:
   â””â”€ Disable feature flag (instant)

Rollback decision criteria:
â”œâ”€ Error rate spike (>1% errors)
â”œâ”€ Latency increase (p99 > SLO)
â”œâ”€ User complaints (support tickets)
â””â”€ Business metrics drop (conversion rate)
```

**Automated Rollback:**

```python
# Automated rollback (monitor metrics)
import time

def monitor_deployment(deployment_id):
    """Monitor deployment, rollback if metrics unhealthy"""
    
    start_time = time.time()
    rollback_threshold = 5  # Rollback after 5 failed checks
    failed_checks = 0
    
    while time.time() - start_time < 3600:  # Monitor for 1 hour
        # Check error rate
        error_rate = get_error_rate()  # From Prometheus/CloudWatch
        
        # Check latency
        p99_latency = get_p99_latency()
        
        # Decision
        if error_rate > 0.01:  # >1% errors
            failed_checks += 1
            logger.warning(f"High error rate: {error_rate:.2%}")
        elif p99_latency > 500:  # >500ms
            failed_checks += 1
            logger.warning(f"High latency: {p99_latency}ms")
        else:
            failed_checks = 0  # Reset on success
        
        # Rollback if threshold exceeded
        if failed_checks >= rollback_threshold:
            logger.error("Deployment unhealthy, rolling back...")
            rollback_deployment(deployment_id)
            send_alert("Automated rollback triggered")
            return False
        
        time.sleep(60)  # Check every minute
    
    logger.info("Deployment healthy, monitoring complete")
    return True

def rollback_deployment(deployment_id):
    """Rollback deployment"""
    # Kubernetes rollback
    os.system(f"kubectl rollout undo deployment/{deployment_id}")
    
    # Or Blue-Green rollback
    os.system(f"kubectl patch service myapp-service -p '{{\"spec\":{{\"selector\":{{\"version\":\"blue\"}}}}}}'")
    
    # Or feature flag rollback
    ld_client.update_flag('new-feature', False)
```

**Rollback Checklist:**

```
Pre-deployment:
â˜ Rollback plan documented (steps to revert)
â˜ Database migrations reversible (downgrade script)
â˜ Feature flags in place (instant disable)
â˜ Monitoring alerts configured (error rate, latency)
â˜ Rollback tested in staging

During rollback:
â˜ Identify issue (error logs, metrics)
â˜ Notify team (Slack, PagerDuty)
â˜ Execute rollback (code, database, or feature flag)
â˜ Verify rollback (metrics return to normal)
â˜ Communicate to users (status page, email)

Post-rollback:
â˜ Root cause analysis (what went wrong?)
â˜ Fix issue (code change, data fix)
â˜ Test fix in staging
â˜ Re-deploy with fix
â˜ Document lessons learned
```

---

## Best Practices Summary

```
CI/CD:
âœ“ Automate everything (build, test, deploy)
âœ“ Fast feedback (tests run in <10 minutes)
âœ“ Build once, deploy many (same artifact to staging/prod)
âœ“ Smoke tests after deployment (health checks)
âœ“ Monitoring + alerting (detect issues early)
âœ— Don't deploy untested code (CI must pass)
âœ— Don't deploy on Fridays (hard to rollback on weekend)
âœ— Don't skip staging (test in production-like environment)

Deployment Strategies:
âœ“ Blue-Green for critical services (instant rollback)
âœ“ Canary for gradual validation (low risk)
âœ“ Feature flags for decoupling (deploy â‰  release)
âœ“ Automated rollback (monitor metrics, rollback on failure)
âœ— Don't deploy everything at once (gradual rollout)
âœ— Don't ignore monitoring (blind deployments risky)

Schema Migrations:
âœ“ Backward compatible (old code still works)
âœ“ Small migrations (one change per migration)
âœ“ Reversible migrations (downgrade script)
âœ“ Test in staging (verify before production)
âœ“ Lock-free migrations (avoid table locks)
âœ— Don't drop columns immediately (3-stage migration)
âœ— Don't rename columns directly (add, dual-write, remove)
âœ— Don't run migrations during peak traffic (off-hours)

Data Migrations:
âœ“ Backfill in batches (avoid overloading database)
âœ“ Dual-writes during migration (write to old + new)
âœ“ Shadow reads for verification (compare old vs new)
âœ“ Idempotent backfills (safe to re-run)
âœ“ Track progress (resume if script crashes)
âœ— Don't backfill during peak traffic (slow queries)
âœ— Don't trust new system immediately (verify first)
âœ— Don't delete old system prematurely (keep for rollback)

Rollback:
âœ“ Document rollback plan (before deployment)
âœ“ Automated rollback (monitor + rollback on failure)
âœ“ Test rollback (staging environment)
âœ“ Feature flag kill switch (instant disable)
âœ“ Database backups (restore if needed)
âœ— Don't panic (follow rollback checklist)
âœ— Don't wait too long (rollback early if issues)
âœ— Don't skip post-mortem (learn from incidents)
```

Complete release engineering and migration guide! ğŸš€ğŸ”„ğŸ“¦