# Networking Basics

## OSI Model Quick Reference

```
Layer 7: Application  (HTTP, FTP, DNS, SMTP)
Layer 6: Presentation (SSL/TLS, Encryption)
Layer 5: Session      (Authentication, Sessions)
Layer 4: Transport    (TCP, UDP)
Layer 3: Network      (IP, Routing)
Layer 2: Data Link    (MAC, Switches)
Layer 1: Physical     (Cables, Signals)

Remember: All People Seem To Need Data Processing
```

---

## 1. TCP vs UDP

### TCP (Transmission Control Protocol)

**Characteristics:**
- **Connection-oriented**: 3-way handshake to establish connection
- **Reliable**: Guaranteed delivery, retransmission on loss
- **Ordered**: Packets arrive in order sent
- **Flow control**: Prevents overwhelming receiver
- **Congestion control**: Adjusts to network conditions
- **Error checking**: Checksum for data integrity
- **Overhead**: Higher (headers, acknowledgments)

**TCP Connection: 3-Way Handshake**
```
Client                          Server
  â”‚                               â”‚
  â”‚â”€â”€â”€â”€â”€â”€â”€ SYN (seq=100) â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  1. Client initiates
  â”‚                               â”‚
  â”‚<â”€â”€â”€â”€ SYN-ACK (seq=200, â”€â”€â”€â”€â”€â”€ â”‚  2. Server acknowledges
  â”‚       ack=101)                â”‚     and sends own SYN
  â”‚                               â”‚
  â”‚â”€â”€â”€â”€â”€â”€â”€ ACK (ack=201) â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  3. Client acknowledges
  â”‚                               â”‚
  â”‚      Connection established   â”‚
  â”‚                               â”‚
  â”‚<â”€â”€â”€â”€â”€â”€ Data exchange â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
  â”‚                               â”‚
  â”‚â”€â”€â”€â”€â”€â”€â”€ FIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  4. Client closes
  â”‚<â”€â”€â”€â”€â”€â”€ ACK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
  â”‚<â”€â”€â”€â”€â”€â”€ FIN â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  5. Server closes
  â”‚â”€â”€â”€â”€â”€â”€â”€ ACK â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
  â”‚                               â”‚
  â”‚      Connection closed        â”‚

Time to establish: 1.5 RTT (Round Trip Time)
```

**TCP Header (20 bytes minimum):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Source Port    â”‚  Dest Port      â”‚ 4 bytes
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      Sequence Number               â”‚ 4 bytes
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   Acknowledgment Number            â”‚ 4 bytes
â”œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Headerâ”‚Flags â”‚Window Sizeâ”‚         â”‚ 4 bytes
â”œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Checksum    â”‚  Urgent Pointer    â”‚ 4 bytes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total: 20 bytes (can be up to 60 with options)
```

**When to Use TCP:**
```
âœ“ Web browsing (HTTP/HTTPS)
âœ“ Email (SMTP, IMAP, POP3)
âœ“ File transfer (FTP, SFTP)
âœ“ Remote access (SSH)
âœ“ Database connections
âœ“ API calls (REST, gRPC)
âœ“ Chat applications (when reliability matters)

Rule: Use when data integrity is critical
```

### UDP (User Datagram Protocol)

**Characteristics:**
- **Connectionless**: No handshake, just send
- **Unreliable**: No delivery guarantee
- **Unordered**: Packets may arrive out of order
- **No flow control**: Can overwhelm receiver
- **No congestion control**: Doesn't adapt to network
- **Minimal error checking**: Basic checksum only
- **Low overhead**: Minimal headers (8 bytes vs 20+ for TCP)

**UDP Header (8 bytes only):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Source Port    â”‚  Dest Port      â”‚ 4 bytes
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚     Length      â”‚    Checksum     â”‚ 4 bytes
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total: 8 bytes (fixed)
```

**When to Use UDP:**
```
âœ“ Video streaming (YouTube, Netflix - some packet loss OK)
âœ“ Video calls (Zoom, Skype - speed > perfection)
âœ“ Online gaming (real-time, stale data useless)
âœ“ DNS queries (single request/response)
âœ“ VoIP (Voice over IP)
âœ“ IoT sensor data (OK to lose occasional reading)
âœ“ Live broadcasts

Rule: Use when speed > reliability, real-time matters
```

### TCP vs UDP Comparison

| Feature | TCP | UDP |
|---------|-----|-----|
| **Connection** | Connection-oriented (handshake) | Connectionless |
| **Reliability** | Guaranteed delivery | Best effort (may lose packets) |
| **Ordering** | Ordered | Unordered |
| **Speed** | Slower (overhead) | Faster (minimal overhead) |
| **Header Size** | 20-60 bytes | 8 bytes |
| **Use Case** | File transfer, web, email | Streaming, gaming, VoIP |
| **Latency** | Higher (acknowledgments) | Lower (no acknowledgments) |
| **Bandwidth** | Efficient (congestion control) | Can be wasteful |

### Example: Sending 1 KB Data

**TCP:**
```
1. Handshake: SYN (50ms) + SYN-ACK (50ms) + ACK (0ms) = 100ms
2. Send 1 KB: 50ms
3. Wait for ACK: 50ms
4. Close: FIN (50ms) + FIN-ACK (50ms) = 100ms

Total time: 100 + 50 + 50 + 100 = 300ms
Overhead: 40 bytes (min headers)
```

**UDP:**
```
1. Send 1 KB: 50ms (no handshake, no waiting)

Total time: 50ms
Overhead: 8 bytes (header only)

6Ã— faster, but no guarantee of delivery!
```

### TCP Optimization: Nagle's Algorithm

**Problem:** Small packets waste bandwidth
```
Without Nagle:
Send "H" â†’ 41 bytes (1 byte data + 40 bytes headers) = 2.4% efficiency
Send "e" â†’ 41 bytes
Send "l" â†’ 41 bytes
Send "l" â†’ 41 bytes
Send "o" â†’ 41 bytes
Total: 205 bytes for 5 bytes of data!
```

**Solution: Nagle's Algorithm**
```
Buffer small writes, send when:
1. Accumulated data â‰¥ MSS (Maximum Segment Size, typically 1460 bytes)
2. OR received ACK for previous packet

Result: Combines "Hello" into 1 packet â†’ 45 bytes (11% efficiency vs 2.4%)

Trade-off:
+ Better bandwidth efficiency
- Higher latency (waiting to accumulate)

Disable for real-time apps:
setsockopt(fd, IPPROTO_TCP, TCP_NODELAY, &flag, sizeof(flag));
```

---

## 2. TLS (Transport Layer Security)

### What is TLS?

**Purpose:** Encrypt data between client and server

```
HTTP  (port 80)  â†’ Unencrypted âŒ Anyone can read
HTTPS (port 443) â†’ Encrypted âœ“ Only client/server can read

TLS provides:
1. Encryption: Data is scrambled
2. Authentication: Verify server identity
3. Integrity: Detect tampering
```

### TLS Handshake (Simplified)

```
Client                                    Server
  â”‚                                          â”‚
  â”‚â”€â”€â”€â”€â”€â”€â”€â”€ ClientHello â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  1. Client: "I support TLS 1.3, 
  â”‚         (TLS versions, ciphers)          â”‚     these encryption methods"
  â”‚                                          â”‚
  â”‚<â”€â”€â”€â”€â”€â”€â”€ ServerHello â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  2. Server: "Let's use TLS 1.3,
  â”‚         (chosen version, cipher)         â”‚     AES-256 encryption"
  â”‚<â”€â”€â”€â”€â”€â”€â”€ Certificate â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚     "Here's my certificate"
  â”‚         (server's public key)            â”‚
  â”‚                                          â”‚
  â”‚â”€â”€â”€â”€â”€â”€â”€â”€ Key Exchange â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚  3. Client: Verify certificate
  â”‚         (client generates session key)   â”‚     Generate shared secret
  â”‚                                          â”‚
  â”‚<â”€â”€â”€â”€â”€â”€â”€ Finished â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  4. Both: Start encrypted
  â”‚â”€â”€â”€â”€â”€â”€â”€â”€ Finished â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚     communication
  â”‚                                          â”‚
  â”‚<â•â•â•â•â•â•â•â• Encrypted Data â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•>â”‚
  â”‚                                          â”‚

TLS 1.3: 1 RTT (Round Trip Time)
TLS 1.2: 2 RTT (slower)
```

### TLS Versions

```
TLS 1.0 (1999): Deprecated, insecure âŒ
TLS 1.1 (2006): Deprecated, insecure âŒ
TLS 1.2 (2008): Widely used, secure âœ“
TLS 1.3 (2018): Latest, fastest, most secure âœ“âœ“

TLS 1.3 improvements:
â”œâ”€ Faster: 1-RTT handshake (vs 2-RTT in TLS 1.2)
â”œâ”€ 0-RTT resumption: Instant reconnection
â”œâ”€ Simpler: Removed weak ciphers
â””â”€ More secure: Forward secrecy mandatory
```

### TLS Performance Impact

**Overhead:**
```
Latency:
â”œâ”€ Handshake: +100-200ms (1-2 RTT)
â”œâ”€ Encryption/decryption: +1-2ms per request
â””â”€ Total: ~100-200ms for first request

CPU:
â”œâ”€ Handshake: High (asymmetric crypto)
â”œâ”€ Bulk encryption: Low (symmetric crypto, ~1-2% CPU)
â””â”€ Hardware acceleration (AES-NI) helps

Connection reuse is critical!
```

**Optimization: TLS Session Resumption**
```
First connection:
Client â†’ Full TLS handshake (200ms) â†’ Server

Later connections (within 24h):
Client â†’ "Remember me? Here's session ID" (50ms) â†’ Server
Server â†’ "Yes! Skip handshake, here's your data" â†’ Client

Result: 4Ã— faster reconnection!

TLS 1.3 0-RTT: Even faster, but has replay attack risks
```

### Certificate Verification

```
Certificate contains:
â”œâ”€ Domain name: example.com
â”œâ”€ Public key: Used to encrypt data
â”œâ”€ Issuer: Certificate Authority (CA) like Let's Encrypt
â”œâ”€ Expiration: Valid until date
â””â”€ Signature: Cryptographic proof from CA

Verification process:
1. Client receives certificate from server
2. Client checks: Is it signed by trusted CA?
3. Client checks: Is domain name correct?
4. Client checks: Has it expired?
5. Client checks: Has it been revoked?

If all pass: âœ“ Trust established
If any fail: âŒ Show "Not Secure" warning
```

---

## 3. HTTP/1.1 vs HTTP/2 vs HTTP/3

### HTTP/1.1 (1997)

**Characteristics:**
```
Protocol: Text-based
Transport: TCP
Multiplexing: No (1 request at a time per connection)
Header compression: No
Server push: No
```

**Problems:**

#### 1. Head-of-Line Blocking
```
Browser wants to load page with:
- HTML file
- 3 CSS files
- 10 images
- 5 JS files

HTTP/1.1 Connection:
Request 1: HTML  â”€â”€â”€â”€â”€â”€â”€â”€> (wait) â”€â”€â”€â”€â”€â”€â”€â”€> Response
Request 2: CSS 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> (wait) â”€â”€> Response
Request 3: CSS 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€> ...

Each request blocks the next! Very slow.

Workaround: Open 6 parallel connections (browser limit)
But still limited and inefficient.
```

#### 2. Header Overhead
```
Each request sends full headers:

Request 1:
GET /page1 HTTP/1.1
Host: example.com
User-Agent: Chrome/120.0.0.0
Accept: text/html,application/xhtml+xml...
Accept-Language: en-US,en;q=0.9
Accept-Encoding: gzip, deflate, br
Cookie: session=abc123...
[~500 bytes of headers]

Request 2:
GET /page2 HTTP/1.1
Host: example.com
User-Agent: Chrome/120.0.0.0
Accept: text/html,application/xhtml+xml...
Accept-Language: en-US,en;q=0.9
Accept-Encoding: gzip, deflate, br
Cookie: session=abc123...
[~500 bytes of SAME headers again!]

Waste of bandwidth, especially for small files.
```

### HTTP/2 (2015)

**Improvements:**
```
Protocol: Binary (not text)
Transport: TCP
Multiplexing: Yes (many requests on 1 connection)
Header compression: Yes (HPACK)
Server push: Yes
Prioritization: Yes
```

#### Multiplexing (Solves Head-of-Line Blocking)
```
HTTP/2 Single Connection:

Stream 1: HTML  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•> Response
Stream 2: CSS 1 â•â•â•â•â•â•â•â•> Response
Stream 3: CSS 2 â•â•â•â•â•â•â•â•â•â•â•> Response
Stream 4: Image â•â•â•â•> Response
Stream 5: JS    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•> Response
...all at the same time!

Result: 2-3Ã— faster page loads
```

#### Header Compression (HPACK)
```
Request 1:
:method: GET
:path: /page1
host: example.com
user-agent: Chrome/120.0.0.0
...
[500 bytes]

Request 2:
:method: GET
:path: /page2
[Reference to previous headers: 50 bytes only!]

Savings: 90% reduction in header size for subsequent requests
```

#### Server Push
```
Client requests: GET /index.html

Server response:
1. Here's index.html
2. Oh, I see it references style.css and script.js
3. I'll push those too, before you even ask!

Result: Eliminates round trips, faster page load

HTTP/1.1: 
Request HTML â†’ Response â†’ Parse â†’ Request CSS â†’ Response (3 RTT)

HTTP/2:
Request HTML â†’ Response (includes pushed CSS) (1 RTT)
```

### HTTP/3 (2020)

**Big Change: Uses QUIC over UDP instead of TCP!**

```
Protocol: Binary
Transport: QUIC (UDP-based)
Multiplexing: Yes (better than HTTP/2)
Header compression: Yes (QPACK, improved HPACK)
Server push: Optional
Encryption: Built-in (TLS 1.3 integrated)
```

**Why UDP? Solves TCP Head-of-Line Blocking**

```
HTTP/2 Problem:
Uses TCP, which ensures order. If 1 packet lost:
Stream 1: Image â•â•â•â•â•â•â•â•[X]â•â•â•> BLOCKED (waiting)
Stream 2: CSS   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•> BLOCKED (waiting)
Stream 3: JS    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•> BLOCKED (waiting)

Even though streams are independent, TCP blocks all!

HTTP/3 (QUIC) Solution:
Uses UDP, streams are truly independent:
Stream 1: Image â•â•â•â•â•â•â•â•[X]â•â•â•> BLOCKED (retransmit)
Stream 2: CSS   â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•> âœ“ Delivered
Stream 3: JS    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•> âœ“ Delivered

Only affected stream blocked, others continue!
```

**Other HTTP/3 Benefits:**

#### 1. Faster Connection Setup
```
HTTP/2 (TCP + TLS 1.3):
TCP handshake: 1 RTT
TLS handshake: 1 RTT
Total: 2 RTT

HTTP/3 (QUIC):
Combined handshake: 1 RTT (QUIC integrates TLS 1.3)
0-RTT resumption: Instant reconnection!
```

#### 2. Connection Migration
```
Scenario: User switches from WiFi to cellular

HTTP/2 (TCP):
TCP connection identified by: (src_ip, src_port, dst_ip, dst_port)
IP changes â†’ Connection drops â†’ Reconnect (slow)

HTTP/3 (QUIC):
Connection identified by: Connection ID (independent of IP)
IP changes â†’ Connection continues seamlessly!

Great for mobile users!
```

### Comparison Table

| Feature | HTTP/1.1 | HTTP/2 | HTTP/3 |
|---------|----------|--------|--------|
| **Year** | 1997 | 2015 | 2020 |
| **Transport** | TCP | TCP | QUIC (UDP) |
| **Format** | Text | Binary | Binary |
| **Multiplexing** | No (1 req/conn) | Yes | Yes (better) |
| **Header Compression** | No | Yes (HPACK) | Yes (QPACK) |
| **Server Push** | No | Yes | Optional |
| **TLS Required** | No | No (but common) | Yes (built-in) |
| **Connection Setup** | 1 RTT (TCP) | 1 RTT (TCP) | 1 RTT (combined) |
| **0-RTT** | No | No | Yes |
| **Head-of-Line** | Yes (app level) | Yes (TCP level) | No |
| **Connection Migration** | No | No | Yes |
| **Performance** | Baseline | 2-3Ã— faster | 3-5Ã— faster |

### When to Use Each

```
HTTP/1.1:
â”œâ”€ Legacy systems
â”œâ”€ Simple services
â””â”€ Not worth upgrading

HTTP/2:
â”œâ”€ Most modern websites âœ“ (Current standard)
â”œâ”€ APIs, microservices
â””â”€ Good balance of support and performance

HTTP/3:
â”œâ”€ Mobile-first apps (connection migration)
â”œâ”€ High-latency networks (lossy connections)
â”œâ”€ Video streaming, gaming
â””â”€ Cutting edge, growing adoption (~30% of web as of 2025)
```

---

## 4. Keep-Alive & Connection Pooling

### HTTP Keep-Alive

**Without Keep-Alive (HTTP/1.0 default):**
```
Request 1:
1. TCP handshake (3-way, 1.5 RTT)
2. TLS handshake (1-2 RTT)
3. Send HTTP request (1 RTT)
4. Receive response
5. Close connection
Total: ~3.5-4.5 RTT

Request 2:
1. TCP handshake again (1.5 RTT)
2. TLS handshake again (1-2 RTT)
3. Send HTTP request (1 RTT)
...

Very wasteful! Each request pays handshake cost.
```

**With Keep-Alive (HTTP/1.1 default):**
```
Request 1:
1. TCP handshake (1.5 RTT)
2. TLS handshake (1-2 RTT)
3. Send HTTP request (1 RTT)
4. Receive response
5. Keep connection open âœ“
Total: ~3.5-4.5 RTT

Request 2 (on same connection):
1. Send HTTP request (1 RTT)
2. Receive response
Total: 1 RTT only!

Request 3, 4, 5... all reuse same connection
Saves 2.5-3.5 RTT per request!
```

**Keep-Alive Configuration:**
```http
HTTP/1.1 (Client):
Connection: keep-alive
Keep-Alive: timeout=60, max=100

HTTP/1.1 (Server response):
Connection: keep-alive
Keep-Alive: timeout=60, max=100

Meaning:
- timeout=60: Keep connection open for 60 seconds of inactivity
- max=100: Allow up to 100 requests on this connection

After 60s idle OR 100 requests: Close connection
```

**Server-Side Configuration:**

**NGINX:**
```nginx
http {
    keepalive_timeout 65;      # 65 seconds idle timeout
    keepalive_requests 100;    # Max 100 requests per connection
    
    # For upstream connections (connection pooling)
    upstream backend {
        server backend1.example.com;
        keepalive 32;          # Keep 32 idle connections in pool
    }
}
```

**Apache:**
```apache
KeepAlive On
MaxKeepAliveRequests 100
KeepAliveTimeout 5
```

**Trade-offs:**
```
Pros:
+ Faster subsequent requests (no handshake)
+ Lower CPU (fewer TLS handshakes)
+ Lower latency (especially for HTTPS)

Cons:
- Server resources tied up (idle connections consume memory)
- Connection limit per server (e.g., 10K max connections)
- Idle connections waste resources

Balance: timeout=60-120s for web, 5-30s for API
```

### Connection Pooling

**Problem:** Creating new connections is expensive

```
Naive approach (no pooling):
Request 1: Create connection â†’ Use â†’ Close
Request 2: Create connection â†’ Use â†’ Close
Request 3: Create connection â†’ Use â†’ Close

Each creation: 3.5-4.5 RTT (TCP + TLS handshake)
```

**Solution: Connection Pool**
```
Connection pool maintains:
- Min connections: 5 (always open)
- Max connections: 20 (can grow to this)
- Idle timeout: 300s (close if unused for 5 min)

Request 1: Get from pool â†’ Use â†’ Return to pool
Request 2: Get from pool â†’ Use â†’ Return to pool
Request 3: Get from pool â†’ Use â†’ Return to pool

No handshake needed! Reuse existing connections.
```

**Connection Pool Lifecycle:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Connection Pool            â”‚
â”‚                                     â”‚
â”‚  [Conn1] [Conn2] [Conn3] [Conn4]  â”‚ â† Idle connections
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                   â”‚ â† In-use connections
â”‚  â”‚Conn5â”‚ â”‚Conn6â”‚                   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. App needs connection:
   - If idle connection exists: Use it
   - Else if pool < max: Create new connection
   - Else: Wait for connection to become available

2. App finishes request:
   - Return connection to pool (don't close)
   - Connection becomes idle, ready for reuse

3. Idle timeout:
   - If connection idle > 5 min: Close it
   - Maintain min connections always
```

**Example: Database Connection Pool**

**Python (SQLAlchemy):**
```python
from sqlalchemy import create_engine

engine = create_engine(
    'postgresql://user:pass@localhost/db',
    pool_size=10,              # Min connections: 10
    max_overflow=20,           # Can create 20 more (max 30 total)
    pool_timeout=30,           # Wait 30s for connection
    pool_recycle=3600,         # Recycle connection after 1 hour
    pool_pre_ping=True         # Check connection before using
)

# Usage
with engine.connect() as conn:
    result = conn.execute("SELECT * FROM users")
    # Connection automatically returned to pool when done
```

**Java (HikariCP - fastest connection pool):**
```java
HikariConfig config = new HikariConfig();
config.setJdbcUrl("jdbc:postgresql://localhost/db");
config.setUsername("user");
config.setPassword("pass");
config.setMinimumIdle(5);           // Min idle connections
config.setMaximumPoolSize(20);      // Max total connections
config.setIdleTimeout(300000);      // 5 min idle timeout
config.setConnectionTimeout(30000); // 30s wait for connection
config.setMaxLifetime(1800000);     // 30 min max connection age

HikariDataSource ds = new HikariDataSource(config);

// Usage
try (Connection conn = ds.getConnection()) {
    // Use connection
    PreparedStatement ps = conn.prepareStatement("SELECT * FROM users");
    ResultSet rs = ps.executeQuery();
}
// Connection automatically returned to pool
```

**HTTP Connection Pool (Python requests):**
```python
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# Create session with connection pooling
session = requests.Session()

# Configure connection pool
adapter = HTTPAdapter(
    pool_connections=10,  # Number of connection pools
    pool_maxsize=20,      # Connections per pool
    max_retries=Retry(
        total=3,
        backoff_factor=0.3,
        status_forcelist=[500, 502, 503, 504]
    )
)

session.mount('http://', adapter)
session.mount('https://', adapter)

# All requests reuse connections
for i in range(100):
    response = session.get('https://api.example.com/data')
    # Connection returned to pool automatically
```

**Connection Pool Sizing:**
```
Formula (from HikariCP):
connections = ((core_count Ã— 2) + effective_spindle_count)

Example:
- Server: 4 CPU cores, 1 SSD
- connections = (4 Ã— 2) + 1 = 9

Why?
- 2Ã— core count: Accounts for context switching
- + spindle count: Accounts for I/O wait

For cloud/SSD: spindle count = 1
For HDD: spindle count = number of physical disks

Don't over-provision:
- 100 app servers Ã— 20 connections = 2000 DB connections
- Database may only support 1000-2000 connections
- Use PgBouncer/ProxySQL as connection pooler in between
```

---

## 5. NAT (Network Address Translation)

### Why NAT?

**Problem: IPv4 Address Exhaustion**
```
IPv4 addresses: ~4.3 billion (2Â³Â²)
Internet devices: ~50 billion+

Solution: NAT allows many devices to share one public IP
```

### How NAT Works

```
Home Network (Private IPs):
â”œâ”€ Router: 192.168.1.1
â”œâ”€ Laptop: 192.168.1.100
â”œâ”€ Phone:  192.168.1.101
â””â”€ TV:     192.168.1.102

ISP assigns router: 203.0.113.42 (1 public IP)

When laptop visits google.com:

1. Laptop â†’ Router:
   Source: 192.168.1.100:54321
   Dest:   142.250.80.46:443 (Google)

2. Router (NAT) â†’ Google:
   Source: 203.0.113.42:12345 (rewrites!)
   Dest:   142.250.80.46:443
   
   Router tracks: 12345 â†’ 192.168.1.100:54321

3. Google â†’ Router:
   Source: 142.250.80.46:443
   Dest:   203.0.113.42:12345

4. Router (NAT) â†’ Laptop:
   Source: 142.250.80.46:443
   Dest:   192.168.1.100:54321 (looks up mapping)

Result: Multiple devices share 1 public IP!
```

### NAT Translation Table

```
Public IP:Port    â†’  Private IP:Port      Protocol  Timeout
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
203.0.113.42:12345 â†’ 192.168.1.100:54321   TCP      300s
203.0.113.42:12346 â†’ 192.168.1.101:44444   TCP      300s
203.0.113.42:12347 â†’ 192.168.1.100:55555   UDP      60s
203.0.113.42:12348 â†’ 192.168.1.102:33333   TCP      300s

If no activity for timeout: Remove mapping
```

### Types of NAT

#### 1. SNAT (Source NAT)
```
Changes source IP (outbound traffic)

Client (private) â†’ NAT â†’ Server (public)
Source: 192.168.1.100 â†’ 203.0.113.42

Used by: Home routers, corporate firewalls
```

#### 2. DNAT (Destination NAT)
```
Changes destination IP (inbound traffic)

Client (public) â†’ NAT â†’ Server (private)
Dest: 203.0.113.42:80 â†’ 192.168.1.50:8080

Used by: Port forwarding, load balancers
```

#### 3. PAT (Port Address Translation) / NAT Overload
```
Many private IPs â†’ 1 public IP (most common)
Uses different ports to distinguish connections

Example:
192.168.1.100:54321 â†’ 203.0.113.42:12345
192.168.1.101:54321 â†’ 203.0.113.42:12346
192.168.1.102:54321 â†’ 203.0.113.42:12347
```

### NAT in Cloud (AWS Example)

```
VPC (Virtual Private Cloud):
â”œâ”€ Public Subnet: 10.0.1.0/24
â”‚   â””â”€ EC2 with public IP: 54.123.45.67
â”œâ”€ Private Subnet: 10.0.2.0/24
â”‚   â”œâ”€ EC2-1: 10.0.2.10 (no public IP)
â”‚   â””â”€ EC2-2: 10.0.2.11 (no public IP)
â””â”€ NAT Gateway: 54.234.56.78 (in public subnet)

Private EC2 wants to access internet:
EC2-1 (10.0.2.10) â†’ NAT Gateway â†’ Internet
                    (rewrites source to 54.234.56.78)

Internet cannot initiate connection to private EC2 (security)
```

**Benefits:**
```
+ Security: Private IPs not directly accessible
+ IP conservation: Many servers share few public IPs
+ Flexibility: Change internal IPs without affecting external

Drawbacks:
- No inbound connections (unless configured)
- Port exhaustion: ~65K ports per public IP
- Added latency (translation overhead)
```

---

## 6. Anycast

### What is Anycast?

**Unicast vs Anycast:**
```
Unicast: 1 IP â†’ 1 specific server
Example: 192.168.1.100 â†’ Server A only

Anycast: 1 IP â†’ Multiple servers (nearest one responds)
Example: 1.1.1.1 â†’ Cloudflare DNS server closest to you
```

### How Anycast Works

```
Cloudflare announces 1.1.1.1 from multiple locations:

        User in NYC
            â”‚
            â”‚ Query: Who has 1.1.1.1?
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚            â”‚
         Router          â”‚
            â”‚            â”‚
   "1.1.1.1 is 5 hops"  â”‚ "1.1.1.1 is 20 hops"
    via NYC datacenter  â”‚  via London datacenter
            â”‚            â”‚
            â†“            â†“
      [NYC Server]   [London Server]
       1.1.1.1        1.1.1.1
       
Router picks shortest path: NYC (5 hops)

User in London:
Similar process â†’ Routed to London server (1.1.1.1)

Same IP, different servers, based on network proximity!
```

### Anycast Routing

```
Global Anycast Deployment:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Internet (BGP Routing)          â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚      â”‚      â”‚      â”‚
   [US-East] [US-West] [EU] [ASIA]
   1.1.1.1   1.1.1.1   1.1.1.1  1.1.1.1
   
Each datacenter announces the same IP (1.1.1.1)
BGP routes users to nearest datacenter automatically
```

**BGP (Border Gateway Protocol) Advertisement:**
```
Each datacenter:
"I can reach 1.1.1.1 via my AS (Autonomous System)"

Internet routers:
- Compare routes to 1.1.1.1
- Pick shortest AS path
- Route traffic there

Result: Automatic geo-distribution!
```

### Use Cases

#### 1. DNS (Domain Name System)
```
Cloudflare: 1.1.1.1
Google: 8.8.8.8
Quad9: 9.9.9.9

Anycast benefits:
+ Low latency: Route to nearest server
+ High availability: If 1 server down, traffic auto-routes to next nearest
+ DDoS mitigation: Distribute attack across all servers
```

#### 2. CDN (Content Delivery Network)
```
Cloudflare, Akamai, Fastly use anycast

User requests: https://cdn.example.com/image.jpg
â”œâ”€ DNS resolves to anycast IP: 104.18.0.1
â”œâ”€ BGP routes to nearest CDN edge
â””â”€ Edge server responds (low latency)

Benefits: Fast, reliable content delivery
```

#### 3. DDoS Mitigation
```
Without Anycast:
Attacker â†’ 1 server â†’ Overwhelmed âŒ

With Anycast:
Attacker â†’ Multiple servers globally â†’ Distributed load âœ“

Each server handles fraction of attack
Easier to absorb and mitigate
```

### Anycast vs Load Balancer

```
Load Balancer (Layer 4/7):
â”œâ”€ Single IP in 1 location
â”œâ”€ Distributes traffic among local servers
â”œâ”€ Application-aware routing
â”œâ”€ Session persistence
â””â”€ Health checks

Anycast (Layer 3):
â”œâ”€ Same IP in multiple locations
â”œâ”€ Routes to nearest location (network-level)
â”œâ”€ No session persistence (stateless)
â”œâ”€ Automatic failover (via BGP)
â””â”€ Simpler, but less control

Often used together:
Anycast â†’ Route to nearest datacenter
Load Balancer â†’ Distribute within datacenter
```

---

## 7. DNS (Domain Name System)

### What is DNS?

**Problem:** Computers use IP addresses, humans use names

```
You type: https://www.google.com
Browser needs: 142.250.80.46 (IP address)

DNS: Phone book of the internet
google.com â†’ 142.250.80.46
```

### DNS Hierarchy

```
                    Root (.)
                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚            â”‚            â”‚
        .com          .org         .net      â† Top-Level Domains (TLD)
          â”‚            â”‚            â”‚
     â”Œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  google  amazon                             â† Second-Level Domains
     â”‚      â”‚
  â”Œâ”€â”€â”¼â”€â”€â”  â””â”€â”€â”€â”€â”€â”
www mail  drive  aws                         â† Subdomains

Full domain: www.google.com
           = www.google.com.  (trailing dot = root)
```

### DNS Query Process

```
User types: www.example.com

1. Browser cache: Check if IP already known
   â””â”€ Hit: Use cached IP (instant)
   â””â”€ Miss: Continue to step 2

2. OS cache: Check /etc/hosts or system DNS cache
   â””â”€ Hit: Use cached IP
   â””â”€ Miss: Continue to step 3

3. Recursive resolver (ISP DNS or 8.8.8.8):
   "I'll find the IP for you"
   
   3a. Resolver cache: Do I already know this?
       â””â”€ Hit: Return IP (fast)
       â””â”€ Miss: Start recursive lookup

4. Root nameserver (.):
   Query: "Where's .com?"
   Response: "Ask .com nameserver at 192.5.6.30"

5. TLD nameserver (.com):
   Query: "Where's example.com?"
   Response: "Ask example.com nameserver at 93.184.216.34"

6. Authoritative nameserver (example.com):
   Query: "What's IP of www.example.com?"
   Response: "93.184.216.34"

7. Resolver â†’ Browser: "IP is 93.184.216.34"
   â””â”€ Caches result for TTL (e.g., 300 seconds)

8. Browser: Connect to 93.184.216.34

Total time: 
- Cached: <1ms
- Uncached: 50-200ms (multiple round trips)
```

### DNS Record Types

```
A Record: Domain â†’ IPv4 address
example.com.  300  IN  A  93.184.216.34

AAAA Record: Domain â†’ IPv6 address
example.com.  300  IN  AAAA  2606:2800:220:1:248:1893:25c8:1946

CNAME Record: Alias â†’ Canonical name
www.example.com.  300  IN  CNAME  example.com.

MX Record: Mail server
example.com.  300  IN  MX  10 mail.example.com.

TXT Record: Arbitrary text (SPF, DKIM, verification)
example.com.  300  IN  TXT  "v=spf1 include:_spf.google.com ~all"

NS Record: Nameserver for domain
example.com.  300  IN  NS  ns1.example.com.

SOA Record: Start of Authority (zone info)
example.com.  300  IN  SOA  ns1.example.com. admin.example.com. ...

Format: <domain> <TTL> <class> <type> <data>
TTL: Time To Live (seconds to cache)
```

### DNS TTL (Time To Live)

```
TTL = How long to cache DNS response

Low TTL (60s):
+ Can change IPs quickly (for migrations, failover)
- More DNS queries (higher load, cost, latency)

High TTL (86400s = 24 hours):
+ Fewer DNS queries (lower load, cost, latency)
- Slow IP changes (old IP cached for 24 hours)

Typical:
â”œâ”€ Static sites: 3600-86400s (1-24 hours)
â”œâ”€ API endpoints: 300-600s (5-10 minutes)
â”œâ”€ Frequently changing: 60-300s (1-5 minutes)
â””â”€ During migration: 60s (1 minute)

Example migration:
1. Week before: Lower TTL to 60s
2. Migration day: Change IP
3. Wait 60s: Old entries expire
4. After migration: Raise TTL back to 3600s
```

### DNS Load Balancing

**Round Robin DNS:**
```
example.com has multiple A records:

example.com.  300  IN  A  192.0.2.1
example.com.  300  IN  A  192.0.2.2
example.com.  300  IN  A  192.0.2.3

DNS resolver returns all IPs (or rotates them)
Client picks one (often first)

Query 1: Client gets [192.0.2.1, 192.0.2.2, 192.0.2.3] â†’ Uses .1
Query 2: Client gets [192.0.2.2, 192.0.2.3, 192.0.2.1] â†’ Uses .2
Query 3: Client gets [192.0.2.3, 192.0.2.1, 192.0.2.2] â†’ Uses .3

Simple load distribution, but:
- No health checks (dead server still in DNS)
- Uneven distribution (depends on client behavior)
- Not real load balancing (DNS level only)
```

**GeoDNS (Geo-based routing):**
```
User location â†’ Different IP

User in US:
example.com â†’ 192.0.2.1 (US datacenter)

User in EU:
example.com â†’ 198.51.100.1 (EU datacenter)

User in Asia:
example.com â†’ 203.0.113.1 (Asia datacenter)

Benefits:
+ Low latency (nearest datacenter)
+ Data residency (GDPR compliance)
+ Disaster recovery (regional failover)

Providers: AWS Route 53, Cloudflare, NS1
```

### DNS Security

**DNS Hijacking:**
```
Attacker compromises DNS:
example.com â†’ 192.0.2.1 (legitimate)
           â†’ 198.51.100.99 (attacker's server)

User thinks they're on example.com, but they're not!

Prevention: DNSSEC
```

**DNSSEC (DNS Security Extensions):**
```
Adds cryptographic signatures to DNS records

Query: www.example.com
Response: 93.184.216.34 + Digital Signature

Client verifies signature:
âœ“ Signature valid: Trust IP
âœ— Signature invalid: Reject (possible attack)

Drawback: Complex, not widely adopted yet
```

**DNS over HTTPS (DoH) / DNS over TLS (DoT):**
```
Problem: DNS queries are unencrypted (anyone can see)
ISP can see: User visited google.com, facebook.com, etc.

Solution: Encrypt DNS queries

DoT (Port 853):
Client â”€â”€[TLS]â”€â”€> DNS Server
         Encrypted DNS query

DoH (Port 443):
Client â”€â”€[HTTPS]â”€â”€> DNS Server
         Looks like regular HTTPS traffic

Benefits:
+ Privacy: ISP can't see DNS queries
+ Integrity: Can't tamper with DNS responses
+ Censorship resistance: Harder to block

Providers: Cloudflare (1.1.1.1), Google (8.8.8.8)
```

---

## 8. IP Allowlists (Whitelists)

### What is IP Allowlist?

**Only specified IPs can access resource**

```
Database:
â”œâ”€ Allowlist: [192.0.2.10, 192.0.2.11, 192.0.2.12]
â””â”€ Deny all others

Result:
âœ“ Request from 192.0.2.10: Allowed
âœ— Request from 203.0.113.50: Denied
```

### Use Cases

#### 1. Database Access
```
Production database:
â”œâ”€ Only allow: Application servers (10.0.1.0/24)
â””â”€ Deny: Public internet, office network

Benefits:
+ Security: Reduce attack surface
+ Compliance: Meet audit requirements
```

#### 2. Admin Panels
```
Admin dashboard:
â”œâ”€ Only allow: Office IP (203.0.113.42)
â””â”€ Deny: All others

/admin/* â†’ Restricted to 203.0.113.42
```

#### 3. API Rate Limiting
```
Public API:
â”œâ”€ Normal users: 1000 req/hour
â”œâ”€ Allowlisted partners (specific IPs): 100K req/hour
â””â”€ Others: Standard rate limit

Allowlist: [192.0.2.50, 192.0.2.51] â†’ Higher limits
```

### Implementation

**NGINX:**
```nginx
# Allow specific IPs
location /admin {
    allow 203.0.113.42;        # Office IP
    allow 192.0.2.0/24;        # VPN range
    deny all;                  # Deny everyone else
    
    # ... rest of config
}

# Deny specific IPs (blocklist)
location / {
    deny 198.51.100.50;        # Known attacker
    deny 203.0.113.100;        # Banned user
    allow all;                 # Allow everyone else
}
```

**AWS Security Group:**
```
Inbound rules:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Type     â”‚ Port â”‚ Source          â”‚ Description â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SSH      â”‚ 22   â”‚ 203.0.113.42/32 â”‚ Office IP   â”‚
â”‚ HTTPS    â”‚ 443  â”‚ 0.0.0.0/0       â”‚ Public web  â”‚
â”‚ MySQL    â”‚ 3306 â”‚ 10.0.1.0/24     â”‚ App servers â”‚
â”‚ Custom   â”‚ 8080 â”‚ 192.0.2.0/24    â”‚ Monitoring  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

/32 = Single IP (255.255.255.255 mask)
/24 = 256 IPs (255.255.255.0 mask)
/16 = 65,536 IPs (255.255.0.0 mask)
0.0.0.0/0 = All IPs (public internet)
```

**PostgreSQL (pg_hba.conf):**
```
# TYPE  DATABASE  USER      ADDRESS           METHOD
host    all       all       10.0.1.0/24       md5     # App servers
host    all       admin     203.0.113.42/32   md5     # Admin from office
host    all       all       0.0.0.0/0         reject  # Deny all others
```

**Application Level (Express.js):**
```javascript
const allowedIPs = ['192.0.2.10', '192.0.2.11', '203.0.113.42'];

app.use('/admin', (req, res, next) => {
    const clientIP = req.ip || req.connection.remoteAddress;
    
    if (allowedIPs.includes(clientIP)) {
        next(); // Allow
    } else {
        res.status(403).send('Access denied'); // Deny
    }
});
```

### Challenges

#### 1. Dynamic IPs
```
Problem: Office IP changes, VPN IPs rotate

Solutions:
â”œâ”€ Use IP ranges (/24 instead of /32)
â”œâ”€ VPN with static IP
â”œâ”€ Alternative: Use VPN or bastion host
â””â”€ Alternative: OAuth/JWT instead of IP allowlist
```

#### 2. Cloud Auto-scaling
```
Problem: App servers scale, IPs change

Solutions:
â”œâ”€ Use CIDR range (10.0.0.0/16)
â”œâ”€ Use security groups (AWS/GCP)
â””â”€ Service mesh (mTLS instead of IP-based)
```

#### 3. NAT/Proxy
```
Problem: Multiple users behind same NAT IP

User A (good) â”€â”
User B (bad)  â”€â”¤â”€> NAT Router (203.0.113.42) â”€> Server
User C (good) â”€â”˜

Can't distinguish users, all appear as 203.0.113.42

Solution: Use authentication + IP allowlist
```

#### 4. IPv6
```
IPv4: 203.0.113.42 (32 bits)
IPv6: 2001:0db8:85a3::8a2e:0370:7334 (128 bits)

Allowlist both:
â”œâ”€ IPv4: 203.0.113.0/24
â””â”€ IPv6: 2001:0db8:85a3::/64

Note: IPv6 ranges are huge (/64 = 18 quintillion IPs!)
```

### Best Practices

```
âœ“ Use CIDR ranges, not individual IPs (easier management)
âœ“ Document each allowlist entry (why it's there)
âœ“ Review allowlist quarterly (remove unused entries)
âœ“ Combine with authentication (defense in depth)
âœ“ Log denied attempts (detect attacks)
âœ“ Use internal tools to manage allowlists (not manual edits)
âœ— Don't rely solely on IP allowlists (IPs can be spoofed/changed)
âœ— Don't allowlist 0.0.0.0/0 (defeats the purpose!)
```

---

## Quick Reference

### Common Ports

```
20/21:  FTP (File Transfer)
22:     SSH (Secure Shell)
23:     Telnet (insecure, deprecated)
25:     SMTP (Email sending)
53:     DNS (Domain Name System)
80:     HTTP (Web)
110:    POP3 (Email retrieval)
143:    IMAP (Email retrieval)
443:    HTTPS (Secure Web)
465:    SMTPS (Secure Email)
993:    IMAPS (Secure IMAP)
3306:   MySQL
5432:   PostgreSQL
6379:   Redis
8080:   HTTP alternate (often used for apps)
27017:  MongoDB
```

### Network Troubleshooting

```
Check connectivity:
$ ping google.com

Check DNS:
$ nslookup google.com
$ dig google.com

Check route:
$ traceroute google.com

Check open ports:
$ telnet example.com 80
$ nc -zv example.com 80

Check listening ports:
$ netstat -tuln
$ ss -tuln

Test HTTP:
$ curl -v https://example.com

Test TLS:
$ openssl s_client -connect example.com:443
```

### Performance Checklist

```
â˜ Enable HTTP/2 or HTTP/3 (multiplexing, header compression)
â˜ Enable keep-alive (reuse connections)
â˜ Use connection pooling (database, HTTP clients)
â˜ Enable TLS session resumption (faster reconnections)
â˜ Use CDN with anycast (low latency, high availability)
â˜ Optimize DNS TTL (balance between flexibility and performance)
â˜ Use DNS prefetching (reduce DNS lookup latency)
â˜ Enable compression (gzip, brotli)
â˜ Use TCP fast open (reduce handshake latency)
â˜ Tune TCP window size (better throughput)
```

Perfect networking foundation for system design! ğŸŒ

